<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>R5by&#39;s Blog</title>
  
  <subtitle>Welcome</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://ruby-.github.io/"/>
  <updated>2021-03-11T09:49:33.164Z</updated>
  <id>https://ruby-.github.io/</id>
  
  <author>
    <name>R5by</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>我的鸡动车驾驶证考试笔记</title>
    <link href="https://ruby-.github.io/2021/03/08/driver-test/"/>
    <id>https://ruby-.github.io/2021/03/08/driver-test/</id>
    <published>2021-03-08T12:10:18.000Z</published>
    <updated>2021-03-11T09:49:33.164Z</updated>
    
    <content type="html"><![CDATA[<h1 id="机动车驾驶证学习笔记"><a href="#机动车驾驶证学习笔记" class="headerlink" title="机动车驾驶证学习笔记"></a>机动车驾驶证学习笔记</h1><h2 id="0x00-为啥写这篇blog"><a href="#0x00-为啥写这篇blog" class="headerlink" title="0x00 为啥写这篇blog"></a>0x00 为啥写这篇blog</h2><p>2021年美国驾照换国内驾照，需要考科目一； 以下为本人搜集的知识要点总结，希望能帮看到的人节省学习时间。</p><h4 id="0x01-关于扣分的题"><a href="#0x01-关于扣分的题" class="headerlink" title="0x01. 关于扣分的题"></a>0x01. 关于扣分的题</h4><blockquote><p>记住下面3个扣6分的，其余的都是扣12分的（其他扣分选项见）</p></blockquote><ul><li>违反交通灯</li><li>非法占用应急车道</li><li>未按交通法规避让校车</li></ul><h4 id="0x02-关于酒驾和醉驾"><a href="#0x02-关于酒驾和醉驾" class="headerlink" title="0x02. 关于酒驾和醉驾"></a>0x02. 关于酒驾和醉驾</h4><ul><li><code>20~80mg/100ml</code>定义为酒驾</li><li><code>&gt;80mg/100ml</code>定义为醉驾</li></ul><h4 id="0x03-关于机动车相关的处罚（两种，二选一）"><a href="#0x03-关于机动车相关的处罚（两种，二选一）" class="headerlink" title="0x03. 关于机动车相关的处罚（两种，二选一）"></a>0x03. 关于机动车相关的处罚（两种，二选一）</h4><ul><li>A. 吊销机动车驾驶证</li><li>B. 处200元以上2000元以下罚款</li></ul><p>关于存在以下行为，申领驾驶证有年限限制的常考题目：</p><blockquote><p>假一吊二撤三醉五逃终身</p></blockquote><ul><li>提供虚假材料被发现，1年</li><li>驾驶照被吊销，2年</li><li>发现贿赂被撤销的，3年</li><li>酒驾被查，5年</li><li>肇事逃逸，终身（逃逸或情节严重的，处3年以上7年以下有期徒刑）</li></ul><h4 id="0x04-关于喇叭和灯光"><a href="#0x04-关于喇叭和灯光" class="headerlink" title="0x04. 关于喇叭和灯光"></a>0x04. 关于喇叭和灯光</h4><ul><li><p>居民区等禁止鸣喇叭的区域，不能鸣喇叭；雾天、山区或者四角视野不清，需要鸣喇叭；听见别人鸣喇叭提醒，要鸣喇叭回应</p></li><li><p>机动车在高速公路上行驶，遇有雾、雨、雪、沙尘、冰雹等低能见度气象条件时，应当遵守下列规定：(一)能见度小于200米时，开启雾灯、近光灯、示廓灯和前后位灯，车速不得超过每小时60公里，与同车道前车保持100米以上的距离；(二)能见度小于100米时，开启雾灯、近光灯、示廓灯、前后位灯和<strong>危险报警闪光灯</strong>，车速不得超过每小时40公里，与同车道前车保持50米以上的距离；(三)能见度小于50米时，开启雾灯、近光灯、示廓灯、前后位灯和<strong>危险报警闪光灯</strong>，车速不得超过每小时20公里，并从最近的出口尽快驶离高速公路。</p><p><img src="https://tva1.sinaimg.cn/large/008eGmZEly1gocrs5cp98j30l9054q3x.jpg" alt></p></li><li><p>只有在无照明或照明条件不好，才开<strong>远光灯</strong>；会车<code>&gt;150m</code>就要改成近光灯了</p></li></ul><h4 id="0x05-交通肇事罪和危险驾驶罪"><a href="#0x05-交通肇事罪和危险驾驶罪" class="headerlink" title="0x05. 交通肇事罪和危险驾驶罪"></a>0x05. 交通肇事罪和危险驾驶罪</h4><blockquote><p> 交通事故造成一人以上重伤，负全部或主要责任，具备以下情形之一以交通肇事罪处罚：</p></blockquote><ul><li>（1）酒驾，毒驾</li><li>（2）无证驾驶</li><li>（3）明知有安全装置不全或失灵</li><li>（4）明知无牌证或已报废</li><li>（5）超载行驶</li><li>（6）逃逸</li></ul><blockquote><p>其他的情况属于_危险驾驶罪_，比如<strong>飙车、酒驾、严重超车、违法运输危险化学物品</strong>，相关的处罚为“处拘役并处罚金”</p></blockquote><h4 id="0x06-关于速度"><a href="#0x06-关于速度" class="headerlink" title="0x06. 关于速度"></a>0x06. 关于速度</h4><h6 id="6-1-普通车道"><a href="#6-1-普通车道" class="headerlink" title="6.1 普通车道"></a>6.1 普通车道</h6><p><img src="https://tva1.sinaimg.cn/large/008eGmZEly1gocsac0fhaj30lt04474u.jpg" alt></p><p><img src="https://tva1.sinaimg.cn/large/008eGmZEly1gocsqbglb1j31460jkkjl.jpg" alt></p><h6 id="6-2-高速公路"><a href="#6-2-高速公路" class="headerlink" title="6.2 高速公路"></a>6.2 高速公路</h6><blockquote><ul><li>高速上时速100以上同车道行车要保持<code>&gt;= 100m</code>的车距；车速小于100的，保持<code>&gt;= 50m</code>的车距</li><li>注意：对于有限速牌子的，要以限速牌上的为准</li></ul></blockquote><p><img src="https://pic1.zhimg.com/80/v2-8366c56aec5a1e2578f0052b5d67563c_1440w.jpg" alt></p><p><img src="https://tva1.sinaimg.cn/large/008eGmZEly1goct135nwjj30os0ka1gb.jpg" alt></p><h6 id="6-3-以下情形，最高行驶速度不得超过30"><a href="#6-3-以下情形，最高行驶速度不得超过30" class="headerlink" title="6.3 以下情形，最高行驶速度不得超过30"></a>6.3 以下情形，最高行驶速度不得超过30</h6><ul><li><p>(一)<strong>进出非机动车道</strong>，通过铁路道口、<strong>急弯路</strong>、窄路、窄桥时；</p></li><li><p>(二)<strong>掉头、转弯</strong>、下陡坡时；</p></li><li><p>(三)遇雾、雨、雪、沙尘、冰雹，能见度在50米以内时；</p></li><li><p>(四)<strong>在冰雪、泥泞的道路上行驶时</strong>；</p></li><li><p>(五)<strong>牵引发生故障的机动车时</strong>。</p></li></ul><h6 id="6-4-关于路牌"><a href="#6-4-关于路牌" class="headerlink" title="6.4 关于路牌"></a>6.4 关于路牌</h6><blockquote><p>看速度路牌，<strong>红高蓝低黄建议</strong>； 看路面，<strong>黄高白低黑建议。</strong></p></blockquote><p><img src="https://tva1.sinaimg.cn/large/008eGmZEly1goctbg6pzwj31qu0oakjf.jpg" alt></p><h4 id="0x07-距离题"><a href="#0x07-距离题" class="headerlink" title="0x07. 距离题"></a>0x07. 距离题</h4><blockquote><p>站3口5不停车</p></blockquote><p><img src="https://tva1.sinaimg.cn/large/008eGmZEly1goctds0xxij30kt04sq3u.jpg" alt></p><ul><li>路障的设置距离：</li></ul><p><img src="https://tva1.sinaimg.cn/large/008eGmZEly1goctertshsj30kg030glh.jpg" alt></p><h4 id="0x08-年检题"><a href="#0x08-年检题" class="headerlink" title="0x08. 年检题"></a>0x08. 年检题</h4><ul><li>(一)营运载客汽车5年以内每年检验1次；超过5年的，每6个月检验1次</li><li>(二)载货汽车和大型、中型非营运载客汽车10年以内每年检验1次；超过10年的，每6个月检验1次；</li><li>(三)<strong>小型、微型非营运载客汽车6年以内每2年检验1次；超过6年的，每年检验1次；超过15年的，每6个月检验1次</strong>；</li><li>(四)摩托车4年以内每2年检验1次；超过4年的，每年检验1次；</li><li>(五)拖拉机和其他机动车每年检验1次。</li></ul><h4 id="0x09-关于驾驶证"><a href="#0x09-关于驾驶证" class="headerlink" title="0x09. 关于驾驶证"></a>0x09. 关于驾驶证</h4><h6 id="9-1-实习证"><a href="#9-1-实习证" class="headerlink" title="9.1 实习证"></a>9.1 实习证</h6><p><strong>初次申领</strong>机动车驾驶证和增加准驾车型后的<strong>12个月为实习期</strong>。实习期间注意：</p><p>1.应当在车身后<strong>悬挂统一式样的实习标志</strong></p><p>2.不得驾驶公共汽车、营运客车或执行任务的警车、消防车、救护车、工程救险车以及载有爆炸物品、易燃易爆、化学物品、剧毒或者放射性等危险物品的机动车，且驾驶机动车<strong>不得牵引挂车</strong>。</p><p>3.驾驶机动车上高速公路行驶，要由持相应或者更高准驾车型驾驶证<strong>3年以上的驾驶人陪同。</strong></p><blockquote><p> <strong>实习期内有记分满12分</strong>，注销其实习的准驾车型的驾驶资</p></blockquote><h6 id="9-2-驾驶证有效期"><a href="#9-2-驾驶证有效期" class="headerlink" title="9.2 驾驶证有效期"></a>9.2 驾驶证有效期</h6><ul><li><p>驾驶证有效期分别为<strong>6年、10年、长期</strong>。初次申领为6年，6年内每周期均未达到12分可换发10年；10年内每周期均未达到12分可换长期；</p></li><li><p><strong>需30日内换证</strong>：驾驶员信息发生变化的；驾驶证损毁无法辨认的；</p></li><li><p><strong>需90日内换证：</strong>机动车驾驶证<strong>有效期满</strong>前90日内，向驾驶证<strong>核发地</strong>或核发地以外的的车辆管理所申请换证。</p></li><li><p><strong>驾驶证补证</strong>只能找核发地</p></li><li><p><strong>驾驶证审验</strong></p><p>内容（<strong>和机动车无关</strong>）：1.道路交通安全违法行为、交通事故处理情况；2.身体条件情况；3.道路交通安全违法行为记分满12分后参加学习和考试情况。</p></li></ul><h6 id="9-3-处罚相关"><a href="#9-3-处罚相关" class="headerlink" title="9.3 处罚相关"></a>9.3 处罚相关</h6><blockquote><p><strong>假一吊二撤三醉五逃终身</strong></p></blockquote><p>解释：申领驾照时作<strong>假</strong>（还未拿到手），隔<strong>一</strong>年重新申领；被<strong>吊</strong>销驾照的（属处罚之一），隔<strong>二</strong>年重新申领；被<strong>撤</strong>销驾照的（指不该拿驾照的人取得驾照，收回他的资格叫做“撤销”，比吊销更严重），隔<strong>三</strong>年重新申领。具体如下：</p><ol><li><p>半年内不得申领：如<strong>酒驾</strong>，暂扣6个月驾驶证，处1000-2000元罚款。如<strong>再次酒驾</strong>，处10日一下拘留，处1000-2000元罚款，吊销驾驶证。</p></li><li><p>一年内不得申领：①隐瞒有关情况或提供<strong>虚假材料申领驾照</strong>的；②在<strong>考试过程中有贿赂、舞弊行为</strong>，取消考试资格，已经通过考试的其他科目成绩无效。</p></li><li><p><strong>三年</strong>内不得申领：如<strong>以欺骗、贿赂等不正当手段取得驾照，收缴驾照，撤销驾驶许可。</strong>三年内有<strong>吸毒</strong>、注射毒品或解除强制隔离戒毒未满三年或长期服用依赖性精神药品成瘾未解除的不得申领。</p></li><li><p>五年内不得申领：如<strong>醉驾</strong>，约束至酒醒，吊销驾驶证，追究刑事责任。<strong>饮酒后驾驶营运机动车</strong>，吊销驾驶证，处15日拘留，处5000元罚款。</p></li><li><p>十年内不得申领：醉酒后驾驶营运机动车，约束至酒醒，吊销驾驶证，追究刑事责任；重领驾照后不得驾驶营运车。</p></li><li><p><strong>终身</strong>不得申领：a.<strong>饮酒后或醉酒驾驶发生重大交通事故</strong>；b.造成交通事故后<strong>逃逸</strong>的。（饮酒不驾车，事故先救人，莫让终生悔）c.有器质性心脏病、癫痫病、精神病以及影响肢体活动的神经系统疾病等妨碍安全驾驶疾病</p></li></ol><h4 id="0x10-累计积分制度"><a href="#0x10-累计积分制度" class="headerlink" title="0x10. 累计积分制度"></a>0x10. 累计积分制度</h4><blockquote><p>常见扣分项汇总：</p><ul><li>1分：</li><li>2分：打电话、<strong>高速上</strong>未系安全带（注意一定是高速，否则只罚款50元）</li><li>3分：</li><li>6分：违反信号灯、骗补证、证被扣、不让校车</li><li>12分：酒驾、遮盖车牌、驾驶与准驾不符、逃逸尚不构成犯罪、高速逆行、</li></ul></blockquote><p><img src="https://tva1.sinaimg.cn/large/008eGmZEly1gocuq0giysj319g0rekjm.jpg" alt></p><p><img src="https://tva1.sinaimg.cn/large/008eGmZEly1gocug3wkv9j31ad0u0npf.jpg" alt></p><p><img src="https://tva1.sinaimg.cn/large/008eGmZEly1gocu2eb5e6j319b0u0kjn.jpg" alt></p><p><img src="https://tva1.sinaimg.cn/large/008eGmZEly1gocu1p8bimj31aa0u0npf.jpg" alt></p><h4 id="0x11-各种图标一览"><a href="#0x11-各种图标一览" class="headerlink" title="0x11 各种图标一览"></a>0x11 各种图标一览</h4><p><img src="https://tva1.sinaimg.cn/large/008eGmZEly1gocu83mqymj30u02obqnl.jpg" alt></p><p><img src="https://tva1.sinaimg.cn/large/008eGmZEly1gocu8jf1qvj30u02vrnp1.jpg" alt></p><p><img src="https://tva1.sinaimg.cn/large/008eGmZEly1gocu971ctbj30rs304dxl.jpg" alt></p><p><img src="https://tva1.sinaimg.cn/large/008eGmZEly1gocua8lp6kj30u01637jx.jpg" alt></p><p><img src="https://tva1.sinaimg.cn/large/008eGmZEly1gocuan7qs6j30u01g1as1.jpg" alt></p><p><img src="https://nimg.mnks.cn/yxlimg/2e81d238.jpg" alt></p><h4 id="0x12-交警手势一览图"><a href="#0x12-交警手势一览图" class="headerlink" title="0x12 交警手势一览图"></a>0x12 交警手势一览图</h4><p><img src="https://tva1.sinaimg.cn/large/008eGmZEly1godyxet21qj30sg0bv7ap.jpg" alt></p><h4 id="0x13-汽车仪表盘指示灯"><a href="#0x13-汽车仪表盘指示灯" class="headerlink" title="0x13 汽车仪表盘指示灯"></a>0x13 汽车仪表盘指示灯</h4><p><img src="https://tva1.sinaimg.cn/large/008eGmZEly1gog3ltbs84j30l70lwteh.jpg" alt></p><h4 id="其他：一些facts记忆"><a href="#其他：一些facts记忆" class="headerlink" title="其他：一些facts记忆"></a>其他：一些facts记忆</h4><ul><li><p>跟驾驶证有关的，都是去<strong>核发地</strong>;跟（机动车）行驶证相关的，都是去车辆<strong>登记地</strong></p></li><li><p>所有的交通违规违章行为现在都视为<em>违法行为</em>, 追究<em>刑事责任</em></p></li><li><p>转弯让直行，右转让左转（危险的先走，相类似的还有靠山体一侧让不靠山体的先行，上坡让下坡）；都是直行无交通灯时候，在右侧的车先走;</p></li><li><p><strong>*初次申领</strong>车型：大型客车、中型客车不行，大型货车可以；</p></li><li><p>未悬挂号码牌，未放置检验合格标志、保险标志或者未携带行驶证、机动车驾驶证。（<strong>口诀：“两证两标一牌”</strong>才上路，缺一样依法把<strong>车扣</strong>）</p></li><li><p><strong>判有期徒刑：（口诀：事故没死人，3年以下。死了人，3-7年。人因逃逸致死，7年。）</strong></p></li><li><p>驻车制动系统就是手刹，显示“p”时是制动状态，显示“！”是出现故障？</p></li><li><p>下长坡要用抵挡发动机制动，否则持续使用刹车会造成刹车片发热，丧失制动能力（<em>制动器</em> 就是 <strong>刹车</strong>）</p></li><li><p>机动车涉水应该<strong>间断轻踏</strong>制动板，提高刹车片温度从而蒸发一部分水分，恢复制动</p></li><li><p>注意区别黄色“警示”和蓝色“指示”的区别，黄色是“注意行人”，蓝色表示“人行横道”</p><p><img src="https://tva1.sinaimg.cn/large/008eGmZEly1gog416g2shj31880omh0x.jpg" alt></p></li><li><p>“牌检保行驾”不可缺，否则交警可以依法扣留车辆。分别为牌照、安检合格标志、保险标志、行驶证、驾驶证。</p></li><li><p>小型自动挡汽车（C2）准驾车型包括：小型、微型自动挡载客汽车以及小型、微型自动挡货车</p></li><li><p>接受审验的情况为（1）检验年限到期或转到异地换证 （2）事故造成人员伤亡未被吊销； 扣满12分不是审检而是再教育</p></li><li><p>高速上疲倦必须去休息区或服务区休息，不能随便停靠路边</p></li><li><p>禁止直行标志加上某些车型的含义是禁止这类车通过</p><p><img src="https://tva1.sinaimg.cn/large/008eGmZEly1godgbvmxwaj30di0hcgqn.jpg" alt></p></li><li><p>正确的握方向盘手法为9点3点</p></li><li><p>只要中间有图像不管什么都叫“中心圈”，例如：</p><img src="https://tva1.sinaimg.cn/large/008eGmZEly1gog41dc3x5j30u00qb755.jpg" style="zoom:30%;"></li><li><p>科目一完成后，准考证明有效期为3年；初次申领驾证实习期为12个月</p></li><li><p>普通逆行记3分，高速逆行记12分</p></li><li><p>两弯反向，三弯连续</p><p><img src="https://tva1.sinaimg.cn/large/008eGmZEly1godwh3t3a9j30a806ot8t.jpg" alt></p></li><li><p>救助全身起火的燃烧伤员应该<strong>喷冷水灭火</strong>；在无绷带的条件下<strong>不可以</strong>使用细绳包扎；</p></li><li><p>各种灯光的标识</p><p><img src="https://tva1.sinaimg.cn/large/008eGmZEly1godx2a47tzj30by07u3yk.jpg" alt></p></li><li><p>驾驶员连续驾驶不得超过4个小时</p></li><li><p>前方有人行横道的道路标志：</p><p><img src="https://tva1.sinaimg.cn/large/008eGmZEly1gody84yaohj30c908at94.jpg" alt></p></li></ul><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC8xMDIzMzQ5NTM=" title="https://zhuanlan.zhihu.com/p/102334953">1. https://zhuanlan.zhihu.com/p/102334953<i class="fa fa-external-link"></i></span></p><p><span class="exturl" data-url="aHR0cHM6Ly93d3cuanN5a3MuY29tL2tzL2NhYTExMC5odG0=" title="https://www.jsyks.com/ks/caa110.htm">2. https://www.jsyks.com/ks/caa110.htm<i class="fa fa-external-link"></i></span></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;机动车驾驶证学习笔记&quot;&gt;&lt;a href=&quot;#机动车驾驶证学习笔记&quot; class=&quot;headerlink&quot; title=&quot;机动车驾驶证学习笔记&quot;&gt;&lt;/a&gt;机动车驾驶证学习笔记&lt;/h1&gt;&lt;h2 id=&quot;0x00-为啥写这篇blog&quot;&gt;&lt;a href=&quot;#0x00-为啥
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>五分钟学会tmux</title>
    <link href="https://ruby-.github.io/2021/03/06/tmux/"/>
    <id>https://ruby-.github.io/2021/03/06/tmux/</id>
    <published>2021-03-06T12:20:11.000Z</published>
    <updated>2021-03-06T13:43:53.180Z</updated>
    
    <content type="html"><![CDATA[<p>5分钟快速学习上手tmux；tmux你看懂这一篇就够了…</p><h2 id="啥是tmux"><a href="#啥是tmux" class="headerlink" title="啥是tmux"></a>啥是tmux</h2><p>一句话，将传统的命令行终端中窗口（window， 即一个terminal的视窗）与会话（session，泛指人机交互行为，比如一个SSH长连接任务）分离的工具。macos下安装：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">brew install tmux</span><br></pre></td></tr></table></figure><h2 id="用tmux啥好处"><a href="#用tmux啥好处" class="headerlink" title="用tmux啥好处"></a>用tmux啥好处</h2><ul><li>第一，方便分离窗口和会话，使得离开窗口不影响会话；</li><li>第二，方便整合工作环境，根据需求划分不同的命令行环境（比如，做一个python开发环境下的命令终端窗口集合）；</li><li>第三，通过插件保存工作环境，方便跟踪工作进度。</li></ul><h3 id="tmux基本概念（一张图秒懂）："><a href="#tmux基本概念（一张图秒懂）：" class="headerlink" title="tmux基本概念（一张图秒懂）："></a>tmux基本概念（一张图秒懂）：</h3><blockquote><p>注意区别这里面的窗口跟terminal自己的窗口。terminal自己的窗口指的是你使用tmux的窗口，而这里的窗口是指每个tmux下建立的工作环境</p></blockquote><p><img src="https://tva1.sinaimg.cn/large/008eGmZEly1goah0rb2xgj32c00t4b29.jpg" alt="image"></p><p><img src="https://tva1.sinaimg.cn/large/008eGmZEly1goaipriz07j31nk0qsnke.jpg" alt></p><ul><li>第一，开启和关闭tmux</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 开启</span></span><br><span class="line">tmux</span><br><span class="line"></span><br><span class="line"><span class="comment"># 关闭并退出tmux（如果需要）</span></span><br><span class="line">tmux <span class="built_in">kill</span>-server</span><br></pre></td></tr></table></figure><p>tmux操作会话常用的按键组合为<code>ctrl+b +s</code>为列出全部的会话，可以使用<code>↑↓←→ + Enter</code>键选择；除此以外的常用命令包括：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 列出当前全部已建会话</span></span><br><span class="line">tmux ls</span><br><span class="line"><span class="comment"># 新建一个会话</span></span><br><span class="line">tmux new -s &lt;session_name&gt;</span><br><span class="line"><span class="comment"># 绑定当前terminal窗口到某个tmux会话（尚未进入任何tmux会话）</span></span><br><span class="line">tmux a -t &lt;session_name&gt;</span><br><span class="line"><span class="comment"># 重命名某个对话</span></span><br><span class="line">tmux rename-session -t &lt;old_name&gt; &lt;new_name&gt;</span><br><span class="line"><span class="comment"># 退出当前会话</span></span><br><span class="line">tmux detach</span><br><span class="line"><span class="comment"># 结束某个会话（慎用）</span></span><br><span class="line">tmux <span class="built_in">kill</span>-session -t &lt;session_name&gt;</span><br></pre></td></tr></table></figure><p>tmux操作窗口常用的按键组合为<code>ctrl+b + n</code> 或 <code>ctrl+b + p</code>向前或者向后选择窗口，<code>ctrl+d</code>关闭当前窗口以及<code>ctrl+b + w</code>选择窗口；除此以外的常用命令包括：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 新建一个窗口</span></span><br><span class="line">tmux new-window -n &lt;window_name&gt;</span><br><span class="line"><span class="comment"># 列出当前会话下的全部窗口</span></span><br><span class="line">tmux list-windows</span><br><span class="line"><span class="comment"># 重命名当前窗口</span></span><br><span class="line">tmux rename-window &lt;new_name&gt;</span><br></pre></td></tr></table></figure><h3 id="使用pane，好嗨哟"><a href="#使用pane，好嗨哟" class="headerlink" title="使用pane，好嗨哟"></a>使用pane，好嗨哟</h3><p>以上都是比较常规的操作，学会了基本上能玩的很嗨了。如果还想更快乐，就需要学习一下pane的概念，但也不是太复杂，熟悉vim的朋友也很容易上手。</p><p>简单来说，pane就是把当前的一个tmux窗口进一步划分成若干块；好处就是可以配合命令观察，比如左边issue一个commend，左边pane时刻使用<code>htop</code>观察资源情况，右边跑任务啥的：</p><p><img src="https://tva1.sinaimg.cn/large/008eGmZEly1goahykabdoj32im0kynpd.jpg" alt="image-2"></p><p>那么，常用的pane的命令除了使用<code>ctrl+b + ↑↓←→</code>来回横跳，还有使用<code>ctrl+b + %</code>以及<code>ctrl+b +&quot;</code>或纵或横隔开窗口等。</p><blockquote><p>以上快捷键也可以用命令代替，可以根据个人喜好选择合适自己的玩法</p></blockquote><h2 id="我的tmux配置"><a href="#我的tmux配置" class="headerlink" title="我的tmux配置"></a>我的tmux配置</h2><p>正如大家所猜想的那样，tmux也有属于自己的配置文件，就在<code>~/.tmux.conf</code>里。下面分享一下我自己的配置，请盆友们按需自取：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## ~/.tmux.conf</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Change the prefix key to C-a</span></span><br><span class="line"><span class="comment"># set -g prefix C-a                          </span></span><br><span class="line"><span class="comment"># unbind C-b                                 </span></span><br><span class="line"><span class="comment"># bind C-a send-prefix</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># List of plugins</span></span><br><span class="line"><span class="built_in">set</span> -g @plugin <span class="string">'tmux-plugins/tpm'</span></span><br><span class="line"><span class="built_in">set</span> -g @plugin <span class="string">'tmux-plugins/tmux-sensible'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># kye bindings</span></span><br><span class="line"><span class="comment"># Use Alt-arrow keys to switch panes</span></span><br><span class="line"><span class="comment"># bind -n C-h select-pane -L</span></span><br><span class="line"><span class="comment"># bind -n C-l select-pane -R</span></span><br><span class="line"><span class="comment"># bind -n C-k select-pane -U</span></span><br><span class="line"><span class="comment"># bind -n C-j select-pane -D</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># restore sessions at crush</span></span><br><span class="line"><span class="built_in">set</span> -g @plugin <span class="string">'tmux-plugins/tmux-resurrect'</span></span><br><span class="line"><span class="built_in">set</span> -g @plugin <span class="string">'tmux-plugins/tmux-continuum'</span></span><br><span class="line"><span class="comment"># restore vim/neovim session</span></span><br><span class="line"><span class="built_in">set</span> -g @resurrect-stragegy-vim <span class="string">'session'</span></span><br><span class="line"><span class="built_in">set</span> -g @resurrect-stragegy-nvim <span class="string">'session'</span></span><br><span class="line"><span class="comment"># 这个是自动回复 如果不设置需要用lead+ctrl s 保存以及lead+ctrl r恢复</span></span><br><span class="line"><span class="built_in">set</span> -g @continuum-restore <span class="string">'on'</span></span><br><span class="line"><span class="built_in">set</span> -g @resurrect-capture-pane-contents <span class="string">'on'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Other examples:</span></span><br><span class="line"><span class="comment"># set -g @plugin 'github_username/plugin_name'</span></span><br><span class="line"><span class="comment"># set -g @plugin 'git@github.com:user/plugin'</span></span><br><span class="line"><span class="comment"># set -g @plugin 'git@bitbucket.com:user/plugin'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Initialize TMUX plugin manager (keep this line at the very bottom of tmux.conf)</span></span><br><span class="line">run <span class="string">'~/.tmux/plugins/tpm/tpm'</span></span><br></pre></td></tr></table></figure><h2 id="脑子不好用记不住怎么办"><a href="#脑子不好用记不住怎么办" class="headerlink" title="脑子不好用记不住怎么办"></a>脑子不好用记不住怎么办</h2><p>嗯，好问题，我也一样。啥命令一学就忘，不然你以为我为啥写这篇blog… </p><p>一个傻瓜式解决方案就是编写一个专属于自己的命令提示函数，忘了的时候随时召唤，刷新一下记忆，如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## ~/.bashrc or ~/.zshrc</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># tmux alias</span></span><br><span class="line"><span class="built_in">alias</span> tnew=<span class="string">'tmux new -s'</span></span><br><span class="line"><span class="built_in">alias</span> tls=<span class="string">'tmux ls'</span></span><br><span class="line"><span class="built_in">alias</span> td=<span class="string">'tmux detach'</span></span><br><span class="line"><span class="built_in">alias</span> ta=<span class="string">'tmux a -t'</span></span><br><span class="line"><span class="built_in">alias</span> tk=<span class="string">'tmux kill-session -t'</span></span><br><span class="line"><span class="built_in">alias</span> ts=<span class="string">'tmux switch -t'</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#tmux self defined help info</span></span><br><span class="line"><span class="function"><span class="title">th</span></span>() &#123;</span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"# Tmux 基本操作"</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"## 基本操作1: 新建pane|window|session："</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"   新建session:\ttmux new -s session_name"</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"   新建window:\tctr+b + c"</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"   新建pane:\tctr+b + %, ctr+b + \""</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"   ------------------------------------------------"</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"## 基本操作2: pane之间|window之间|session之间 切换"</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"   pane之间的切换:\tctr+b + 方向键（或者根据喜好配置一下类似于vim的hjkl键）"</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"   window之间的切换:\tctr+b+n(ext), ctr+b+p(revious) （补充：ctr+b+w)"</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"   session之间的切换:\tctr+b+s (补充：ctr+b+d, tmux attach -t )"</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"   ------------------------------------------------"</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"## 基本操作3: 关闭tmux服务及其他常用命令"</span> </span><br><span class="line">    <span class="built_in">echo</span> <span class="string">'   detach a session:\tctr+b + d 或输入\"exit"'</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">'   quit tmux:\t\ttmux kill-server'</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">'   rename a session:\ttmux rename-session -t &lt;old-session-name&gt; &lt;new-session-name&gt;'</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><p><span class="exturl" data-url="aHR0cHM6Ly93d3cucnVhbnlpZmVuZy5jb20vYmxvZy8yMDE5LzEwL3RtdXguaHRtbA==" title="https://www.ruanyifeng.com/blog/2019/10/tmux.html">1. https://www.ruanyifeng.com/blog/2019/10/tmux.html<i class="fa fa-external-link"></i></span></p><p><span class="exturl" data-url="aHR0cDovL2xvdWlzemhhaS5naXRodWIuaW8vMjAxNy8wOS8zMC90bXV4Lw==" title="http://louiszhai.github.io/2017/09/30/tmux/">2. http://louiszhai.github.io/2017/09/30/tmux/<i class="fa fa-external-link"></i></span></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;5分钟快速学习上手tmux；tmux你看懂这一篇就够了…&lt;/p&gt;
&lt;h2 id=&quot;啥是tmux&quot;&gt;&lt;a href=&quot;#啥是tmux&quot; class=&quot;headerlink&quot; title=&quot;啥是tmux&quot;&gt;&lt;/a&gt;啥是tmux&lt;/h2&gt;&lt;p&gt;一句话，将传统的命令行终端中窗口（w
      
    
    </summary>
    
    
      <category term="work efficiency" scheme="https://ruby-.github.io/categories/work-efficiency/"/>
    
    
      <category term="tmux, linux" scheme="https://ruby-.github.io/tags/tmux-linux/"/>
    
  </entry>
  
  <entry>
    <title>Kubeedge Examples (Temperature Sensor Demo)</title>
    <link href="https://ruby-.github.io/2020/03/04/kubeedge-temperature-demo/"/>
    <id>https://ruby-.github.io/2020/03/04/kubeedge-temperature-demo/</id>
    <published>2020-03-04T07:45:05.000Z</published>
    <updated>2020-03-05T04:54:34.000Z</updated>
    
    <content type="html"><![CDATA[<p>This post explain the setup of our kubeedge temperature demo in lab, which can be found in <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2t1YmVlZGdlL2V4YW1wbGVzL3RyZWUvbWFzdGVyL2t1YmVlZGdlLXRlbXBlcmF0dXJlLWRlbW8=" title="https://github.com/kubeedge/examples/tree/master/kubeedge-temperature-demo">here<i class="fa fa-external-link"></i></span>. I’ve spent too much time on this due to the lack of documentation, thus I’ve documented our experience steps in details here just in case someone may find this useful.</p><h2 id="Pre-requisites"><a href="#Pre-requisites" class="headerlink" title="Pre-requisites"></a>Pre-requisites</h2><p>To run this demo, a valid deployment of Kubeedge on K8s cluster is required. If you haven’t met this pre-requisite, please refer to my previous posts on “k3s+kubeedge setups” on deploying k3s (v0.10.2) and kubeedge (v1.0.0). Or, you may stay with me in this post to follow how did we setup kubeedge in release 1.1.0 starting from <a href>here</a>.</p><p>To check whether your kubeedge cluster is functioning in the correct manner, simply do:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># $KUBEEDGE=&#123;your-path-to-kubeedge&#125;</span></span><br><span class="line"><span class="built_in">cd</span> <span class="variable">$KUBEEDGE</span>/build</span><br><span class="line"></span><br><span class="line"><span class="comment"># change deployment.yaml to deployment-armv7.yaml if your edge node is on the RPi 3</span></span><br><span class="line">kc apply -f deployment.yaml</span><br></pre></td></tr></table></figure><p>If everything is done correctly, the nginx deployment should be up and running and you may verify the pod’s status by <code>kc get pod</code>. At this point, you may start to follow their documentation on deploying the examples, you’ll probably get stuck on some errors and couldn’t figure where goes wrong, if that’s the case for you please continue reading (o.w. you may close this page and free to leave :D).</p><h2 id="Upgrade-to-Kubeedge-v1-1-0"><a href="#Upgrade-to-Kubeedge-v1-1-0" class="headerlink" title="Upgrade to Kubeedge v1.1.0"></a>Upgrade to Kubeedge v1.1.0</h2><p>At the beginning when I failed following their documentation, I thought that was caused by the incompatibility of the versions (the demo came out several months after they release v1.0.0). So I made a decision to upgrade the kubeedge version from v1.0.0 to v1.1.0. This section states one way in which you may deploy kubeedge v1.1.0 with a valid k3s master in your own environment.</p><blockquote><p>Use <code>kc -n kube-system get pod</code> to get a list of deployed k3s master pods. Refer to my previous posts to see how to disable the modules we do not need. Check the log of your coredns to ensure there is no error message (o.w. flush the iptable and kill these pods twice to solve the issues related to udp connection).</p></blockquote><p>The deployment of cloudcore of kubeedge v1.1.0 is similar to v1.0.0, just remember to change all “edgecontroller” in the yaml files under <code>build/cloud/</code> path to “edgecore”. Also, the creation of device/deviceModel CRDs is no longer an optional in this version, as soon as the cloudcore is up, one should immediately apply these resources before moving on:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create CRDs: devices_v1alpha1_device.yaml &amp; devices_v1alpha1_devicemodel.yaml</span></span><br><span class="line"><span class="comment"># A quick reference can be found here: https://github.com/kubeedge/kubeedge/blob/master/docs/proposals/device-crd.md</span></span><br><span class="line">kc create -f build/crds/devices</span><br></pre></td></tr></table></figure><p>For the edge part, we suggest deploying both edgecore and mqtt broker at bare metal:</p><ul><li><p>1) To bring up a MQTT broker, simply install mosquitto and issue <code>mosquitto -v -p 1883</code> (We suggest to keep the terminal in order to verify the log infos);</p></li><li><p>2) Cross-compile the edgecore and scp it to the RPi 3;</p></li><li><p>3) Copy and modify the <code>edge/conf</code> files to the Rpi 3 to match your own environment (make sure the <code>conf/</code> stays at the same path with the edgecore binary);</p></li><li><p>4) Launch the edgecore from terminal by <code>./edgecore</code> to keep watching the log information.</p></li></ul><p>If you are not sure whether your <code>conf/edge.yaml</code> file is correct, you may refer my settings in below (change wherever I’ve marked in angle brackets):</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">mqtt:</span></span><br><span class="line"><span class="attr">    server:</span> <span class="attr">tcp://&lt;mqtt-server-ip&gt;:1883</span> <span class="comment"># external mqtt broker url.</span></span><br><span class="line"><span class="attr">    internal-server:</span> <span class="attr">tcp://127.0.0.1:1884</span> <span class="comment"># internal mqtt broker url.</span></span><br><span class="line"><span class="attr">    mode:</span> <span class="number">2</span> <span class="comment"># 0: internal mqtt broker enable only. 1: internal and external mqtt broker enable. 2: external mqtt broker enable only.</span></span><br><span class="line"><span class="attr">    qos:</span> <span class="number">0</span> <span class="comment"># 0: QOSAtMostOnce, 1: QOSAtLeastOnce, 2: QOSExactlyOnce.</span></span><br><span class="line"><span class="attr">    retain:</span> <span class="literal">false</span> <span class="comment"># if the flag set true, server will store the message and can be delivered to future subscribers.</span></span><br><span class="line"><span class="attr">    session-queue-size:</span> <span class="number">100</span> <span class="comment"># A size of how many sessions will be handled. default to 100.</span></span><br><span class="line"></span><br><span class="line"><span class="attr">edgehub:</span></span><br><span class="line"><span class="attr">    websocket:</span></span><br><span class="line"><span class="attr">        url:</span> <span class="attr">wss://&lt;cloudcore-server-ip&gt;:&lt;port&gt;/e632aba927ea4ac2b575ec1603d56f10/&lt;edge-node-id&gt;/events</span></span><br><span class="line"><span class="attr">        certfile:</span> <span class="string">/etc/kubeedge/certs/edge.crt</span></span><br><span class="line"><span class="attr">        keyfile:</span> <span class="string">/etc/kubeedge/certs/edge.key</span></span><br><span class="line"><span class="attr">        handshake-timeout:</span> <span class="number">30</span> <span class="comment">#second</span></span><br><span class="line"><span class="attr">        write-deadline:</span> <span class="number">15</span> <span class="comment"># second</span></span><br><span class="line"><span class="attr">        read-deadline:</span> <span class="number">15</span> <span class="comment"># second</span></span><br><span class="line"><span class="attr">    quic:</span></span><br><span class="line"><span class="attr">        url:</span> <span class="string">&lt;cloudcore-server-ip&gt;:10001</span></span><br><span class="line"><span class="attr">        cafile:</span> <span class="string">/etc/kubeedge/ca/rootCA.crt</span></span><br><span class="line"><span class="attr">        certfile:</span> <span class="string">/etc/kubeedge/certs/edge.crt</span></span><br><span class="line"><span class="attr">        keyfile:</span> <span class="string">/etc/kubeedge/certs/edge.key</span></span><br><span class="line"><span class="attr">        handshake-timeout:</span> <span class="number">30</span> <span class="comment">#second</span></span><br><span class="line"><span class="attr">        write-deadline:</span> <span class="number">15</span> <span class="comment"># second</span></span><br><span class="line"><span class="attr">        read-deadline:</span> <span class="number">15</span> <span class="comment"># second</span></span><br><span class="line"><span class="attr">    controller:</span></span><br><span class="line"><span class="attr">        protocol:</span> <span class="string">websocket</span> <span class="comment"># websocket, quic</span></span><br><span class="line"><span class="attr">        heartbeat:</span> <span class="number">15</span>  <span class="comment"># second</span></span><br><span class="line"><span class="attr">        project-id:</span> <span class="string">e632aba927ea4ac2b575ec1603d56f10</span></span><br><span class="line"><span class="attr">        node-id:</span> <span class="string">&lt;edge-node-id&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="attr">edged:</span></span><br><span class="line"><span class="attr">    register-node-namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">    hostname-override:</span> <span class="string">&lt;edge-node-id&gt;</span> </span><br><span class="line"><span class="attr">    interface-name:</span> <span class="string">&lt;edge-node-net-interface&gt;</span></span><br><span class="line"><span class="attr">    edged-memory-capacity-bytes:</span> <span class="number">7852396000</span></span><br><span class="line"><span class="attr">    node-status-update-frequency:</span> <span class="number">10</span> <span class="comment"># second</span></span><br><span class="line"><span class="attr">    device-plugin-enabled:</span> <span class="literal">false</span></span><br><span class="line"><span class="attr">    gpu-plugin-enabled:</span> <span class="literal">false</span></span><br><span class="line"><span class="attr">    image-gc-high-threshold:</span> <span class="number">80</span> <span class="comment"># percent</span></span><br><span class="line"><span class="attr">    image-gc-low-threshold:</span> <span class="number">40</span> <span class="comment"># percent</span></span><br><span class="line"><span class="attr">    maximum-dead-containers-per-container:</span> <span class="number">1</span></span><br><span class="line"><span class="attr">    docker-address:</span> <span class="attr">unix:///var/run/docker.sock</span></span><br><span class="line"><span class="attr">    runtime-type:</span> <span class="string">docker</span></span><br><span class="line"><span class="attr">    remote-runtime-endpoint:</span> <span class="attr">unix:///var/run/dockershim.sock</span></span><br><span class="line"><span class="attr">    remote-image-endpoint:</span> <span class="attr">unix:///var/run/dockershim.sock</span></span><br><span class="line"><span class="attr">    runtime-request-timeout:</span> <span class="number">2</span></span><br><span class="line"><span class="attr">    podsandbox-image:</span> <span class="string">&lt;select-right-one-from-following-comments&gt;</span> <span class="comment"># kubeedge/pause:3.1 for x86 arch , kubeedge/pause-arm:3.1 for arm arch, kubeedge/pause-arm64 for arm64 arch</span></span><br><span class="line"><span class="attr">    image-pull-progress-deadline:</span> <span class="number">60</span> <span class="comment"># second</span></span><br><span class="line"><span class="attr">    cgroup-driver:</span> <span class="string">cgroupfs</span> <span class="comment"># <span class="doctag">NOTE:</span> Need to be consistent with your docker cgroup driver, o.w. the node status will always be "NotReady"</span></span><br><span class="line"><span class="attr">    node-ip:</span> <span class="string">""</span></span><br><span class="line"><span class="attr">    cluster-dns:</span> <span class="string">""</span></span><br><span class="line"><span class="attr">    cluster-domain:</span> <span class="string">""</span></span><br><span class="line"></span><br><span class="line"><span class="attr">mesh:</span></span><br><span class="line"><span class="attr">    loadbalance:</span></span><br><span class="line"><span class="attr">        strategy-name:</span> <span class="string">RoundRobin</span></span><br></pre></td></tr></table></figure><p>If the configuration is correct, you should be able to see some log information about connection between kubeedge cloudcore and edgecore, and edgecore with the mqtt broker. Generally speaking, the edgecore is responsible to get the sensor reading through MQTT subscription, and then push that data upstream to the cloudcore. So next we are about to show how to create/deploy a kubeedge mapper to collect and publish the sensor data.</p><blockquote><p>Don’t forget to create the node resource via <code>kc create -f build/node.json</code> to include this newly started edge node to the cluster. If correct, one should be able to see the node in “Ready” status.</p></blockquote><h2 id="The-Kubeedge-Mapper"><a href="#The-Kubeedge-Mapper" class="headerlink" title="The Kubeedge Mapper"></a>The Kubeedge Mapper</h2><p>The mapper source code for this demo is contained in <code>$GOPATH/src/github.com/kubeedge/examples/kubeedge-temperature-demo/temperature-mapper/main.go</code>. Since the size of this source is quite small, we suggest to obtain its source code and directly build it on your edge node for deployment. However, if you simply need it for deployment, feel free to grab mine in <code>r5by/kubeedge-temperature-mapper:v1.0.0</code> for RPi 3 (o.w. you may use <code>docker build -t &lt;your-image-name&gt; .</code> command to prepare the mapper for your own usage).</p><blockquote><p>Remember, if you use <code>docker build</code> command, your result image can be only deployed on that architecture (e.g. build on RPi 3, only run on arm). </p></blockquote><p>The mapper basically does two things, read sensor data from the pin and publish the readings to the mqtt broker. A detailed explanation of each modules can be found <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2t1YmVlZGdlL2t1YmVlZGdlL2Jsb2IvbWFzdGVyL2RvY3MvbW9kdWxlcy9jbG91ZC9kZXZpY2VfY29udHJvbGxlci5tZA==" title="https://github.com/kubeedge/kubeedge/blob/master/docs/modules/cloud/device_controller.md">here<i class="fa fa-external-link"></i></span>. And the correct way to connect the sensor in the real physical world is also shown in their <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2t1YmVlZGdlL2V4YW1wbGVzL3RyZWUvbWFzdGVyL2t1YmVlZGdlLXRlbXBlcmF0dXJlLWRlbW8=" title="https://github.com/kubeedge/examples/tree/master/kubeedge-temperature-demo">github<i class="fa fa-external-link"></i></span> repo. Do the following on your cloud side once you obtain the source codes:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> <span class="variable">$GOPATH</span>/src/github.com/kubeedge/examples/kubeedge-temperature-demo/crds</span><br><span class="line"></span><br><span class="line">kubectl apply -f devicemodel.yaml</span><br><span class="line">kubectl apply -f device.yaml</span><br></pre></td></tr></table></figure><p><em>NOTE</em>: Here, stop! I need you to verify if kubeedge indeed creates the crd instances by:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Go to the same path where you put your edgecore on your edge node, you should be able to see an `edge.db` file,</span></span><br><span class="line">sqlite3 edge.db</span><br><span class="line"></span><br><span class="line"><span class="comment"># Inside the sqlite CLI interface:</span></span><br><span class="line">&gt; .table <span class="comment"># you should see several tables including devices</span></span><br><span class="line">&gt; .header on</span><br><span class="line">&gt; .mode column</span><br><span class="line">&gt; <span class="built_in">read</span> * from devices; <span class="comment"># if nothing is listed here, you fail!</span></span><br><span class="line">&gt; .<span class="built_in">exit</span> <span class="comment"># quit sqlite after verification</span></span><br></pre></td></tr></table></figure><p>Now, what could cause your troubles here are:</p><ul><li>1) You misconfigured your crd instances. Double check your <code>device.yaml</code> file, it’s like this:</li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">devices.kubeedge.io/v1alpha1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Device</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">temperature</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line"><span class="attr">    description:</span> <span class="string">'temperature'</span></span><br><span class="line"><span class="attr">    manufacturer:</span> <span class="string">'test'</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  deviceModelRef:</span></span><br><span class="line"><span class="attr">    name:</span> <span class="string">temperature-model</span></span><br><span class="line"><span class="attr">  nodeSelector:</span></span><br><span class="line"><span class="attr">    nodeSelectorTerms:</span></span><br><span class="line"><span class="attr">      - matchExpressions:</span></span><br><span class="line"><span class="attr">          - key:</span> <span class="string">''</span></span><br><span class="line"><span class="attr">            operator:</span> <span class="string">In</span></span><br><span class="line"><span class="attr">            values:</span></span><br><span class="line"><span class="bullet">              -</span> <span class="string">&lt;your-node-id&gt;</span> <span class="comment"># NOTE here, this should be your node id other than its label!!</span></span><br><span class="line"><span class="attr">status:</span></span><br><span class="line"><span class="attr">  twins:</span></span><br><span class="line"><span class="attr">    - propertyName:</span> <span class="string">temperature-status</span></span><br><span class="line"><span class="attr">      desired:</span></span><br><span class="line"><span class="attr">        metadata:</span></span><br><span class="line"><span class="attr">          type:</span> <span class="string">string</span></span><br><span class="line"><span class="attr">        value:</span> <span class="string">''</span></span><br></pre></td></tr></table></figure><ul><li>2) You made some changes according to 1) but still it’s not there. This is because the kubeedge doesn’t re-apply your changes if you simply do <code>kc apply -f crds</code>. You will need to first delete these crds then re-create them to enable the writing into this database.</li></ul><p>Once you solve the above problems, nothing shall bother you any more. Simple create this mapper and follow the rest of official documentation to read your sensor from upstream:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> <span class="variable">$GOPATH</span>/src/github.com/kubeedge/examples/kubeedge-temperature-demo/</span><br><span class="line"></span><br><span class="line"><span class="comment"># Please enter the following details in the deployment.yaml :-</span></span><br><span class="line"><span class="comment">#    1. ~Replace &lt;edge_node_name&gt; with the name of your edge node at spec.template.spec.nodeSelector.name~</span></span><br><span class="line"><span class="comment">#       <span class="doctag">NOTE:</span> &lt;edge_node_name&gt; here actually means the node's label, not its name!!</span></span><br><span class="line"><span class="comment">#    2. Replace &lt;your_image&gt; at spec.template.spec.containers.image</span></span><br><span class="line"></span><br><span class="line">kc create -f deployment.yaml</span><br><span class="line"></span><br><span class="line"><span class="comment"># The mapper will report back the temperature to cloud after updating. Observe the temperature in the cloud side.</span></span><br><span class="line">kc get device temperature -oyaml -w</span><br></pre></td></tr></table></figure><h2 id="Pitfalls-坑-amp-Trouble-Shooting"><a href="#Pitfalls-坑-amp-Trouble-Shooting" class="headerlink" title="Pitfalls(坑) &amp; Trouble Shooting"></a>Pitfalls(坑) &amp; Trouble Shooting</h2><p>You may or may not come across the following problems, and I put here my solutions for your references:</p><ul><li>Q1: Cross-compile failed with errors: “xxx version: does not match version-control timestamp xxx”</li></ul><blockquote><p>A1: Disable go mod solves this, that is, before your build, do <code>export GO111MODULE=off</code>.</p></blockquote><ul><li>Q2: Cross-compile failed on CentOS 7: “ xxx arm-linux-gnueabi-gcc xxx”</li></ul><blockquote><p>A2: CentOS doesn’t support gnu gcc cross compiler well, simple switch to Ubuntu 18.04 solves this issue for me (Trying to use CentOS’s gun cross compiler doesn’t work for me)</p></blockquote><ul><li>Q3: Where to find the Kubeedge documentation to my target version?</li></ul><blockquote><p>A3: The official documentation is a mess found <span class="exturl" data-url="aHR0cHM6Ly9yZWFkdGhlZG9jcy5vcmcvcHJvamVjdHMva3ViZWVkZ2UvZG93bmxvYWRzL3BkZi9sYXRlc3Qv" title="https://readthedocs.org/projects/kubeedge/downloads/pdf/latest/">here<i class="fa fa-external-link"></i></span>. However the references found under <code>doc</code> source folder are closer to the truth…</p></blockquote><ul><li>Q4: Any Kubeedge MQTT references?</li></ul><blockquote><p>A4: <span class="exturl" data-url="aHR0cHM6Ly9rdWJlZWRnZS5yZWFkdGhlZG9jcy5pby9lbi92MS4wLjAvZ3VpZGVzL21lc3NhZ2VfdG9waWNzLmh0bWw=" title="https://kubeedge.readthedocs.io/en/v1.0.0/guides/message_topics.html">Here<i class="fa fa-external-link"></i></span></p></blockquote><ul><li>Q5: Forgot to delete the mapper deployment now it’s always automatically brought up by k3s, what shall I do?</li></ul><blockquote><p>A5: The “etcd” is replaced by sqlite (in default) for k3s. You may manually delete those registered resources in <code>/var/lib/rancher/k3s/server/db/state.db</code> if can’t delete them from <code>kubectl</code> command.</p></blockquote><ul><li>Q6: Give me a quick Sqlite Manual</li></ul><blockquote><p>A6: <span class="exturl" data-url="aHR0cHM6Ly93d3cucnVub29iLmNvbS9zcWxpdGUvc3FsaXRlLXR1dG9yaWFsLmh0bWw=" title="https://www.runoob.com/sqlite/sqlite-tutorial.html">Here<i class="fa fa-external-link"></i></span></p></blockquote><ul><li>Q7: Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?</li></ul><blockquote><p>A7: <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2RvY2tlci9mb3ItbGludXgvaXNzdWVzLzUzNQ==" title="https://github.com/docker/for-linux/issues/535">Refer to this thread<i class="fa fa-external-link"></i></span>; solve by rm the docker related files and restart docker.</p></blockquote><ul><li>Q8: How to check whether MQTT broker can be reached from within another container?</li></ul><blockquote><p>A8: login to the other container and use <code>telnet &lt;mqtt-ip-addr&gt; &lt;mqtt-port&gt;</code> command.</p></blockquote><ul><li>Q9: Understand MQTT server log info.</li></ul><blockquote><p>A9: <span class="exturl" data-url="aHR0cHM6Ly9iaXRlZW5pdS5naXRodWIuaW8vbXF0dC9tb3NxdWl0dG8tbG9nLWFuYWx5c2lzLw==" title="https://biteeniu.github.io/mqtt/mosquitto-log-analysis/">Reference here<i class="fa fa-external-link"></i></span></p></blockquote><ul><li>Q10: What is the <code>qemu-user-static</code> that Kubeedge project uses for cross-compile from within docker?</li></ul><blockquote><p>A10: <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL211bHRpYXJjaC9xZW11LXVzZXItc3RhdGljI3FlbXUtdXNlci1zdGF0aWM=" title="https://github.com/multiarch/qemu-user-static#qemu-user-static">Here<i class="fa fa-external-link"></i></span></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;This post explain the setup of our kubeedge temperature demo in lab, which can be found in &lt;span class=&quot;exturl&quot; data-url=&quot;aHR0cHM6Ly9naXR
      
    
    </summary>
    
    
      <category term="edge computing, cloud computing" scheme="https://ruby-.github.io/categories/edge-computing-cloud-computing/"/>
    
    
      <category term="kubeedge, k3s" scheme="https://ruby-.github.io/tags/kubeedge-k3s/"/>
    
  </entry>
  
  <entry>
    <title>k3s+kubeedge (3) Deploy Edge Core on Raspberry Pi 3</title>
    <link href="https://ruby-.github.io/2020/02/01/kubeedge-on-k3s-3/"/>
    <id>https://ruby-.github.io/2020/02/01/kubeedge-on-k3s-3/</id>
    <published>2020-02-01T07:37:32.000Z</published>
    <updated>2020-02-01T23:13:17.000Z</updated>
    
    <content type="html"><![CDATA[<p>This post finalize the setup of Kubeedge on K3S cluster. The edge part of the Kubeedge connect with the API server through CloudHub in the cloud core (i.e. “edgecontroller”). We will deploy the edgecore on two Raspberry Pi 3 nodes.</p><h2 id="Step-1-Check-the-current-environment"><a href="#Step-1-Check-the-current-environment" class="headerlink" title="Step 1. Check the current environment"></a>Step 1. Check the current environment</h2><p>Before you follow the rest of this post, please make sure you have your k3s master and kubeedge edgecontroller service up &amp; running:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Input: On master node</span></span><br><span class="line"><span class="comment">## Verify the k3s master</span></span><br><span class="line">kc get node</span><br><span class="line"><span class="comment"># Output:</span></span><br><span class="line"><span class="comment"># aces-diamonds-ace.localdomain   Ready      master   116d   v1.16.2-k3s.1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## Verify the edgecontroller</span></span><br><span class="line">kce get svc</span><br><span class="line"><span class="comment"># Output: </span></span><br><span class="line"><span class="comment"># NAME             TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)                          AGE</span></span><br><span class="line"><span class="comment"># edgecontroller   NodePort   10.43.217.231   &lt;none&gt;        10000:30267/TCP,2345:32345/TCP   38m</span></span><br></pre></td></tr></table></figure><p>SSH to your Raspberry Pi and stop the k3s workers (if you have them running at those edge nodes):</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Input: On Rasp Pi</span></span><br><span class="line">./k3s-killall.sh</span><br></pre></td></tr></table></figure><h2 id="Step-2-Cross-compile-evil-or-good"><a href="#Step-2-Cross-compile-evil-or-good" class="headerlink" title="Step 2. Cross-compile: evil or good"></a>Step 2. Cross-compile: evil or good</h2><p>The next step is to build and save edgecore image. This part is kinda messy for the Kubeedge project (吐了个槽). I’ve tried to follow the guide in their official documentation <span class="exturl" data-url="aHR0cHM6Ly9kb2NzLmt1YmVlZGdlLmlvL2VuL2xhdGVzdC9zZXR1cC9zZXR1cC5odG1sI2RlcGxveS10aGUtZWRnZS1ub2Rl" title="https://docs.kubeedge.io/en/latest/setup/setup.html#deploy-the-edge-node">here<i class="fa fa-external-link"></i></span> but failed. If you also confront so many problems like I do when following the official document, I suggest to try the solution as I suggest in below.</p><p>Cross-compile is a feature offered by Kubeedge project out-of-box. However, it doesn’t work as it’s supposed to, at least for my case. First, let’s take a quick look at its README file and I’ll explain what should happen:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> build/edge</span><br><span class="line">vi README.md</span><br></pre></td></tr></table></figure><p>This README file is probably the second worst README instructions you can possibly find all over the github (the worst stays in my own repo). After reading it, little we know about its usefulness. In fact, the script makes use of the docker-compose on setting up both build and deployment environment in mixture, even though it still provides a <code>only_run_edge</code> option, the README instruction mentions nothing about it. After so many trouble shootings, I give up on using the original docker-compose method and adopt the following approach.</p><p>First, since I don’t want to use Rasp Pi to build the project, I use the following commands to cross build the armv7 docker image within my x86_64 master node. The attached <code>run_daemon.sh</code> script provides a way of using <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL211bHRpYXJjaC9xZW11LXVzZXItc3RhdGljI3FlbXUtdXNlci1zdGF0aWM=" title="https://github.com/multiarch/qemu-user-static#qemu-user-static">qemu<i class="fa fa-external-link"></i></span> to achieve such goal. Basically what it does is to simulate a arm-based Docker (but in fact running on a amd host) to build your Dockerfile into images for arm. You probably will confront problems mentioned in <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2dvbGFuZy9nby9pc3N1ZXMvMTUwMzg=" title="https://github.com/golang/go/issues/15038">#15038<i class="fa fa-external-link"></i></span>, <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2t1YmVlZGdlL2t1YmVlZGdlL2lzc3Vlcy8xMDY4" title="https://github.com/kubeedge/kubeedge/issues/1068">#1068<i class="fa fa-external-link"></i></span> and <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2RvY2tlci9jb21wb3NlL2lzc3Vlcy83MTYw" title="https://github.com/docker/compose/issues/7160">#7160<i class="fa fa-external-link"></i></span> if you intend to build directly from Rasp Pi. But before you jump to those discussions, you can try to use my modified Dockerfile to replace the original one found under path <code>build/edge/</code> in order to save some time:</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ARG</span> BUILD_FROM=golang:<span class="number">1.12</span>-alpine3.<span class="number">10</span></span><br><span class="line"><span class="keyword">ARG</span> RUN_FROM=docker:dind</span><br><span class="line"></span><br><span class="line"><span class="keyword">FROM</span> $&#123;BUILD_FROM&#125; AS builder</span><br><span class="line"></span><br><span class="line"><span class="keyword">ARG</span> QEMU_ARCH=x86_64</span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> ./build/edge/tmp/qemu-<span class="variable">$&#123;QEMU_ARCH&#125;</span>-static /usr/bin/</span></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> . /go/src/github.com/kubeedge/kubeedge</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> apk --no-cache update &amp;&amp; \</span></span><br><span class="line"><span class="bash">apk --no-cache upgrade &amp;&amp; \</span></span><br><span class="line"><span class="bash">apk add libc-dev &amp;&amp; \</span></span><br><span class="line"><span class="bash">apk add binutils-gold &amp;&amp; \</span></span><br><span class="line"><span class="bash">apk --no-cache add build-base linux-headers sqlite-dev &amp;&amp; \</span></span><br><span class="line"><span class="bash">CGO_ENABLED=1 go build -v -o /usr/<span class="built_in">local</span>/bin/edge_core -ldflags=<span class="string">"-w -s -extldflags -static"</span> \</span></span><br><span class="line"><span class="bash">/go/src/github.com/kubeedge/kubeedge/edge/cmd</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">FROM</span> $&#123;RUN_FROM&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">LABEL</span><span class="bash"> maintainer=<span class="string">"zhanghongtong &lt;zhanghongtong@foxmail.com&gt;"</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> --from=builder /usr/bin/qemu* /usr/bin/</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">ENV</span> GOARCHAIUS_CONFIG_PATH /etc/kubeedge/edge</span><br><span class="line"><span class="keyword">ENV</span> database.source /var/lib/kubeedge/edge.db</span><br><span class="line"></span><br><span class="line"><span class="keyword">VOLUME</span><span class="bash"> [<span class="string">"/etc/kubeedge/certs"</span>, <span class="string">"/var/lib/edged"</span>, <span class="string">"/var/lib/kubeedge"</span>, <span class="string">"/var/run/docker.sock"</span>]</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> --from=builder /usr/<span class="built_in">local</span>/bin/edge_core /usr/<span class="built_in">local</span>/bin/edge_core</span></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> --from=builder /go/src/github.com/kubeedge/kubeedge/edge/conf /etc/kubeedge/edge/conf</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">ENTRYPOINT</span><span class="bash"> [<span class="string">"edge_core"</span>]</span></span><br></pre></td></tr></table></figure><blockquote><p>The magic button to notice is <code>apk add binutils-gold</code>, refer to the discussions <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2dvb2dsZS9ndmlzb3IvaXNzdWVzLzI2" title="https://github.com/google/gvisor/issues/26">here<i class="fa fa-external-link"></i></span> for more details.</p></blockquote><p>With the Dockerfile modified, issue the following command to build edgecore for your own arm hosts. Or, if you are also using Raspberry Pi 3, feel free to grab my pre-built images from here <code>r5by/kubeedge_edgecore_armv7:v1.0.0</code>.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># build the edgecore for Rasp Pi 3 (arm v7)</span></span><br><span class="line"><span class="built_in">cd</span> build/edge</span><br><span class="line">./run_daemon.sh <span class="built_in">set</span> arch=arm32v7 qemu_arch=arm</span><br><span class="line">./run_daemon.sh build</span><br></pre></td></tr></table></figure><blockquote><p><strong>NOTE</strong>: If you have a Rasp Pi 4 or later, you may need target arm v8. Use <code>./run_daemon.sh set arch=arm64v8 qemu_arch=aarch64</code> instead. If these parameters are not set, by default it builds image for x86_64. The configured parameters will be then written into <code>.env</code> file under the path.</p></blockquote><blockquote><p>If you are not sure whether your build image is indeed for amd or arm, simply use <code>docker inspect &lt;image_id&gt;</code> to check its architecture. Also, if you launch the images on docker with wrong architecture, you will see some error messages like “standard_init_linux.go:xxx: exec user process caused “exec format error””, etc.</p></blockquote><h2 id="Step-3-Launch-edgecore"><a href="#Step-3-Launch-edgecore" class="headerlink" title="Step 3. Launch edgecore"></a>Step 3. Launch edgecore</h2><p>After the edgecore image is prepared, we can now launch the edgecore from the Rasp Pi. Firstly, the certificates and configuration files need to be also available from the edge nodes.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># On master:</span></span><br><span class="line">tar czvf kubecert.tar /etc/kubeedge/</span><br><span class="line">scp kubecert.tar &lt;your_pi_node&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment"># On worker (i.e. Pi):</span></span><br><span class="line"><span class="built_in">cd</span> /</span><br><span class="line">tar zxvf kubecert.tar</span><br></pre></td></tr></table></figure><p>Remember to copy the <code>run_daemon.sh</code> file as well. Then launch the edgecore with the following command:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">./run_daemon.sh only_run_edge cloudhub=&lt;your_cloud_hub_ip&gt;:&lt;port&gt; edgename=edge-node-pi-01 image=<span class="string">"r5by/kubeedge_edgecore_armv7:v1.0.0"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Verify your</span></span><br></pre></td></tr></table></figure><blockquote><p>Obtain the <port> number from master node via command <code>k3s kubectl get svc -n kubeedge</code> as we introduced in the previous post.</port></p></blockquote><p>If you have built your edgecore in the correct architecture and everything works, you should be able to see it’s running within docker at your edge. Switch back to your cloud master and edit a new <code>node.yaml</code> file to let your master detect this newly added edge node.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cd build/edge; vi node.yaml</span></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Node</span><br><span class="line">metadata:</span><br><span class="line">  name: edge-node-pi-01</span><br><span class="line">  labels:</span><br><span class="line">    name: edge-node-pi-01</span><br><span class="line">    node-role.kubernetes.io/edge: <span class="string">""</span></span><br></pre></td></tr></table></figure><p>Save the yaml file and apply with command <code>kc apply -f node.yaml</code>. Deploy the edgecore on the second Rasp Pi node similarly, and if you have done everything correctly, you should be able to see your k3s+kubeedge cluster up and running:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">kc get node</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output:</span></span><br><span class="line"><span class="comment"># aces-diamonds-ace.localdomain   Ready      master   116d   v1.16.2-k3s.1</span></span><br><span class="line"><span class="comment"># edge-node-pi-01                 Ready      edge     20m    v1.10.9-kubeedge-v1.0.0</span></span><br><span class="line"><span class="comment"># edge-node-pi-02                 Ready      edge     4s     v1.10.9-kubeedge-v1.0.0</span></span><br></pre></td></tr></table></figure><h2 id="Step-4-Summery"><a href="#Step-4-Summery" class="headerlink" title="Step 4. Summery"></a>Step 4. Summery</h2><p>In this series of post, we have shown how to deploy Kubeedge on k3s. In the next post, I’ll jump into some interesting examples provided by Kubeedge open source project to explore its wide usages. Please leave in the comments below to let me know if you may have any trouble when following my tutorials on deploying k3s+kubeedge in your own use case. Peace!</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;This post finalize the setup of Kubeedge on K3S cluster. The edge part of the Kubeedge connect with the API server through CloudHub in th
      
    
    </summary>
    
    
      <category term="edge computing, cloud computing" scheme="https://ruby-.github.io/categories/edge-computing-cloud-computing/"/>
    
    
      <category term="kubeedge, k3s" scheme="https://ruby-.github.io/tags/kubeedge-k3s/"/>
    
  </entry>
  
  <entry>
    <title>k3s+kubeedge (2) Deploy the Cloud Core (edgecontroller)</title>
    <link href="https://ruby-.github.io/2020/02/01/kubeedge-on-k3s-2/"/>
    <id>https://ruby-.github.io/2020/02/01/kubeedge-on-k3s-2/</id>
    <published>2020-02-01T06:03:15.000Z</published>
    <updated>2020-02-01T23:13:03.000Z</updated>
    
    <content type="html"><![CDATA[<p>In the previous post, we know how to set up a code-review/debugging environment (some preparations are actually included in this post though). Now, let’s try to bring up the Kubeedge cloudcore (“edgecontroller” as for v1.0.0) on our k3s master. Again, this post assumes you already have a minimal k3s/k8s master up and running at the server, if you don’t know how to do so, feel free to visit my previous posts on guiding you through the k3s setup.</p><h2 id="Step-1-Preparation-–-k3s-revisit"><a href="#Step-1-Preparation-–-k3s-revisit" class="headerlink" title="Step 1. Preparation – k3s revisit"></a>Step 1. Preparation – k3s revisit</h2><p>In my last post, I forgot to mention about my k3s environment (打脸). Since we are using Docker other than Containerd for k3s, I recommend to change the k3s configuration as following (and disable several services that we are not currently using):</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># vi /etc/systemd/system/k3s.service</span></span><br><span class="line">[Unit]</span><br><span class="line">Description=Lightweight Kubernetes</span><br><span class="line">Documentation=https://k3s.io</span><br><span class="line">Wants=network-online.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type=notify</span><br><span class="line">EnvironmentFile=/etc/systemd/system/k3s.service.env</span><br><span class="line">ExecStartPre=-/sbin/modprobe br_netfilter</span><br><span class="line">ExecStartPre=-/sbin/modprobe overlay</span><br><span class="line">ExecStart=/usr/<span class="built_in">local</span>/bin/k3s \</span><br><span class="line">    server \</span><br><span class="line">    --no-deploy traefik \</span><br><span class="line">    --docker \</span><br><span class="line">    --no-deploy servicelb \</span><br><span class="line"></span><br><span class="line">KillMode=process</span><br><span class="line">Delegate=yes</span><br><span class="line">LimitNOFILE=infinity</span><br><span class="line">LimitNPROC=infinity</span><br><span class="line">LimitCORE=infinity</span><br><span class="line">TasksMax=infinity</span><br><span class="line">TimeoutStartSec=0</span><br><span class="line">Restart=always</span><br><span class="line">RestartSec=5s</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure><p>Save the file and reload daemon then restart k3s service:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl restart k3s</span><br><span class="line"></span><br><span class="line"><span class="comment">#Check the k3s is successfully restarted with the modified configurations</span></span><br><span class="line">systemctl status k3s</span><br></pre></td></tr></table></figure><blockquote><p> Traefik is always restarting automatically with k3s. Thus to truly disable it, one should follow the commands mentioned in <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3JhbmNoZXIvazNzL2lzc3Vlcy83MTcjaXNzdWVjb21tZW50LTU0MTg3NjU4OA==" title="https://github.com/rancher/k3s/issues/717#issuecomment-541876588">here<i class="fa fa-external-link"></i></span>.</p></blockquote><h2 id="Step-2-Build-amp-Deploy-cloudimage"><a href="#Step-2-Build-amp-Deploy-cloudimage" class="headerlink" title="Step 2. Build &amp; Deploy cloudimage"></a>Step 2. Build &amp; Deploy cloudimage</h2><p>Feel free to refresh your memory on how to build the Kubeedge cloudimage in my previous post. However if you only wish to test deploy, you may use mine here <code>r5by/kubeedge_edgecontroller:v1.0.0</code>. After the cloudimage is prepared, the next step is to generate certification files:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> build/cloud</span><br><span class="line">../tools/certgen.sh buildSecret | tee ./06-secret.yaml</span><br></pre></td></tr></table></figure><p>This scripts will generate a bunch of ca/crt files under path <code>/etc/kubeedge/</code> and write the secrets to <code>06-secret.yaml</code>. Then next, we should copy and paste the kubeconfig to that location for later usage:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkdir /etc/kubeedge/cloud</span><br><span class="line"><span class="comment"># k3s kubeconfig location</span></span><br><span class="line">cp /etc/rancher/k3s/k3s.yaml /etc/kubeedge/cloud/kubeconfig.yaml</span><br></pre></td></tr></table></figure><h2 id="Step-3-Modify-the-other-yaml-files"><a href="#Step-3-Modify-the-other-yaml-files" class="headerlink" title="Step 3. Modify the other yaml files"></a>Step 3. Modify the other yaml files</h2><p>In the <code>build/cloud</code> path, several yaml files are listed:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> build/cloud/; ls</span><br><span class="line"><span class="comment"># Output:</span></span><br><span class="line"><span class="comment"># 01-namespace.yaml          03-clusterrole.yaml        05-configmap.yaml          07-deployment.yaml         Dockerfile                  README_zh.md</span></span><br><span class="line"><span class="comment"># 02-serviceaccount.yaml     04-clusterrolebinding.yaml 06-secret.yaml             08-service.yaml.example    README.md</span></span><br></pre></td></tr></table></figure><p>Change <code>03-clusterrole.yaml</code> as following:</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRole</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">edgecontroller</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line"><span class="attr">    k8s-app:</span> <span class="string">kubeedge</span></span><br><span class="line"><span class="attr">    kubeedge:</span> <span class="string">edgecontroller</span></span><br><span class="line"><span class="attr">rules:</span></span><br><span class="line"><span class="attr">- apiGroups:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">""</span></span><br><span class="line"><span class="attr">  resources:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">nodes</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">nodes/status</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">configmaps</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">pods</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">pods/status</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">secrets</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">services</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">endpoints</span></span><br><span class="line"><span class="attr">  verbs:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">get</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">list</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">watch</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">update</span></span><br><span class="line"><span class="attr">- apiGroups:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">""</span></span><br><span class="line"><span class="attr">  resources:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">pods</span></span><br><span class="line"><span class="attr">  verbs:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">delete</span></span><br></pre></td></tr></table></figure><p>Change <code>05-configmap.yaml</code> as following:</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">edgecontroller</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">kubeedge</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line"><span class="attr">    k8s-app:</span> <span class="string">kubeedge</span></span><br><span class="line"><span class="attr">    kubeedge:</span> <span class="string">edgecontroller</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="string">controller.yaml:</span> <span class="string">|</span></span><br><span class="line"><span class="string"></span><span class="attr">    controller:</span></span><br><span class="line"><span class="attr">      kube:</span></span><br><span class="line"><span class="attr">        master:</span> <span class="attr">https://kubernetes.default.svc.cluster.local:443</span></span><br><span class="line"><span class="attr">        kubeconfig:</span> <span class="string">/etc/kubeedge/cloud/kubeconfig.yaml</span></span><br><span class="line"><span class="attr">        namespace:</span> <span class="string">""</span></span><br><span class="line"><span class="attr">        content_type:</span> <span class="string">"application/vnd.kubernetes.protobuf"</span></span><br><span class="line"><span class="attr">        qps:</span> <span class="number">5</span></span><br><span class="line"><span class="attr">        burst:</span> <span class="number">10</span></span><br><span class="line"><span class="attr">        node_update_frequency:</span> <span class="number">10</span></span><br><span class="line"><span class="attr">    cloudhub:</span></span><br><span class="line"><span class="attr">      address:</span> <span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span></span><br><span class="line"><span class="attr">      port:</span> <span class="number">10000</span></span><br><span class="line"><span class="attr">      ca:</span> <span class="string">/etc/kubeedge/certs/rootCA.crt</span></span><br><span class="line"><span class="attr">      cert:</span> <span class="string">/etc/kubeedge/certs/edge.crt</span></span><br><span class="line"><span class="attr">      key:</span> <span class="string">/etc/kubeedge/certs/edge.key</span></span><br><span class="line"><span class="attr">      keepalive-interval:</span> <span class="number">30</span></span><br><span class="line"><span class="attr">      write-timeout:</span> <span class="number">30</span></span><br><span class="line"><span class="attr">      node-limit:</span> <span class="number">10</span></span><br><span class="line"><span class="attr">    devicecontroller:</span></span><br><span class="line"><span class="attr">       kube:</span></span><br><span class="line"><span class="attr">         master:</span> <span class="attr">https://kubernetes.default.svc.cluster.local:443</span></span><br><span class="line"><span class="attr">         namespace:</span> <span class="string">""</span></span><br><span class="line"><span class="attr">         content_type:</span> <span class="string">"application/vnd.kubernetes.protobuf"</span></span><br><span class="line"><span class="attr">         qps:</span> <span class="number">5</span></span><br><span class="line"><span class="attr">         burst:</span> <span class="number">10</span></span><br><span class="line"><span class="attr">         kubeconfig:</span> <span class="string">/etc/kubeedge/cloud/kubeconfig.yaml</span></span><br><span class="line">           <span class="string">logging.yaml:</span> <span class="string">|</span></span><br><span class="line"><span class="string"></span><span class="attr">    loggerLevel:</span> <span class="string">"INFO"</span></span><br><span class="line"><span class="attr">    enableRsyslog:</span> <span class="literal">false</span></span><br><span class="line"><span class="attr">    logFormatText:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">    writers:</span> <span class="string">[stdout]</span></span><br><span class="line">  <span class="string">modules.yaml:</span> <span class="string">|</span></span><br><span class="line"><span class="string"></span><span class="attr">    modules:</span></span><br><span class="line"><span class="attr">      enabled:</span> <span class="string">[controller,</span> <span class="string">cloudhub]</span></span><br></pre></td></tr></table></figure><p>Then verify if your <code>06-secret.yaml</code> is consistent with the ca/cert files in path <code>/etc/kubeedge/</code>, also copy and paste the <code>07-deployment.yaml</code> and <code>08-service.yaml</code> files from our last post. </p><p>The configurations are now set. Use the shell script we write in last post to initialize start Kubeedge edgecontroller on the cloud.</p><p>If everything works as expect, you should be able to verify the edgecontroller service is up:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># `kce` alias `k3s kubectl -n kubeedge`</span></span><br><span class="line">kce get pod</span><br><span class="line"><span class="comment">#Output</span></span><br><span class="line"><span class="comment">#NAME                            READY   STATUS    RESTARTS   AGE</span></span><br><span class="line"><span class="comment">#edgecontroller-5dc9955c-p2c7s   1/1     Running   0          5s</span></span><br><span class="line"></span><br><span class="line">kce get svc</span><br><span class="line"><span class="comment">#NAME             TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)                          AGE</span></span><br><span class="line"><span class="comment">#edgecontroller   NodePort   10.43.217.231   &lt;none&gt;        10000:30267/TCP,2345:32345/TCP   27s</span></span><br><span class="line"></span><br><span class="line">kce logs edgecontroller-5dc9955c-p2c7s</span><br><span class="line"><span class="comment"># No error messages should be found...</span></span><br></pre></td></tr></table></figure><h2 id="Step-4-Trouble-Shooting"><a href="#Step-4-Trouble-Shooting" class="headerlink" title="Step 4. Trouble Shooting"></a>Step 4. Trouble Shooting</h2><p>Okay, I understand life is complicated. Unfortunately if you were caught by some weird error messages, don’t panic (even though the compiler does). Check the issues I mentioned in the previous post, and verify carefully each of these yaml files to make sure you understand what should be there. I also listed here several forum posts that may help with your issues:</p><ul><li>1) <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2t1YmVybmV0ZXMvZG5zL2lzc3Vlcy8xMTA=" title="https://github.com/kubernetes/dns/issues/110">DNS issue, not the fix for mine<i class="fa fa-external-link"></i></span></li><li>2) <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2t1YmVybmV0ZXMva3ViZXJuZXRlcy9pc3N1ZXMvNjY0MzI=" title="https://github.com/kubernetes/kubernetes/issues/66432">DNS issue, again not the fix for mine<i class="fa fa-external-link"></i></span></li><li>3) <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2t1YmVybmV0ZXMvbWluaWt1YmUvaXNzdWVzLzQzNTA=" title="https://github.com/kubernetes/minikube/issues/4350">DNS issue, no luck either<i class="fa fa-external-link"></i></span></li><li>4) <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2t1YmVybmV0ZXMva3ViZWFkbS9pc3N1ZXMvMTkzI2lzc3VlY29tbWVudC0zMzAwNjA4NDg=" title="https://github.com/kubernetes/kubeadm/issues/193#issuecomment-330060848">DNS issue, finally works, fix mentioned in here<i class="fa fa-external-link"></i></span></li><li>5) <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3JhbmNoZXIvcmFuY2hlci9pc3N1ZXMvNjEzOQ==" title="https://github.com/rancher/rancher/issues/6139">DNS issue, not works for mine<i class="fa fa-external-link"></i></span></li><li>6) <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3JhbmNoZXIvazNzL2lzc3Vlcy8yNA==" title="https://github.com/rancher/k3s/issues/24">DNS issue, from k3s forum, not a solution for my case<i class="fa fa-external-link"></i></span></li></ul><p>Finally, if you have other questions/problems and solutions, please leave your comments below to share with others. In the next post, I’ll complete the Kubeedge cluster setup with the edgecore setup on both lovely Raspberry Pi’s.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;In the previous post, we know how to set up a code-review/debugging environment (some preparations are actually included in this post tho
      
    
    </summary>
    
    
      <category term="edge computing, cloud computing" scheme="https://ruby-.github.io/categories/edge-computing-cloud-computing/"/>
    
    
      <category term="kubeedge, k3s" scheme="https://ruby-.github.io/tags/kubeedge-k3s/"/>
    
  </entry>
  
  <entry>
    <title>k3s+kubeedge (1) Code Review/Debugging Environment Setup</title>
    <link href="https://ruby-.github.io/2020/01/31/kubeedge-on-k3s-1/"/>
    <id>https://ruby-.github.io/2020/01/31/kubeedge-on-k3s-1/</id>
    <published>2020-01-31T13:25:25.000Z</published>
    <updated>2020-02-01T23:13:40.000Z</updated>
    
    <content type="html"><![CDATA[<p><span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2t1YmVlZGdlL2t1YmVlZGdl" title="https://github.com/kubeedge/kubeedge">Kubeedge<i class="fa fa-external-link"></i></span> is a CNCF open source project that aims at extending the existing orchestration system (Kubernetes)’s container management capability to the edge. It provides core infrastructure support for networking, application deployment and metadata synchronization between cloud and edge along with the Kubernetes project. In this series of posts, we’ll see how to deploy Kubeedge on our existing k3s cluster and set up a code review environment where we may set up breakpoint and step-by-step inspect its functionality. This post focuses on the latter part.</p><p>For the purpose of reading code and more importantly, understanding and fixing the errors, it’s better to have a debugging environment set up first. As for our deployment, we currently have one PC server as the master host to deploy the cloud part, and two Raspberry Pi 3 as the worker nodes to deploy the edge part. The main components of Kubeedge’s cloud/edge parts can be viewed from the structure pictured in below:</p><p><img src="https://github.com/kubeedge/kubeedge/raw/master/docs/images/kubeedge_arch.png" alt="image"></p><p>This post is going to demonstrate how to debug the “cloud core” from within the container at deployment. For the edge core, the procedures are similar. You may also build &amp; debug the code from the code directly, but in my case I personally like to have development environment to be close to my deployment (a.k.a in a docker/container execution environment).</p><blockquote><p>Note: In the previous releases (&lt; v1.0.0) of Kubeedge, the “cloud_core” was named as “edgecontroller” in the code, therefore we will use “edgecontroller” to refer to the “cloud core” in this post because we adopt Kubeedge v1.0.0</p></blockquote><blockquote><p>The following steps assumes your already have a successfully deployed &amp; running k3s cluster (or k8s cluster). All though the master (API server) is required, the worker nodes are not.</p></blockquote><h2 id="Step-1-Preparation"><a href="#Step-1-Preparation" class="headerlink" title="Step 1. Preparation"></a>Step 1. Preparation</h2><p>First download the source to the master PC, and checkout the version 1.0.0 for later usage:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p <span class="variable">$GOPATH</span>/src/github.com/kubeedge</span><br><span class="line"><span class="built_in">cd</span> <span class="variable">$GOPATH</span>/src/github.com/kubeedge</span><br><span class="line">git <span class="built_in">clone</span> git@github.com:kubeedge/kubeedge.git</span><br><span class="line"><span class="comment"># If you only want to compile quickly without using go mod, please set GO111MODULE=off (e.g. export GO111MODULE=off) </span></span><br><span class="line"><span class="built_in">cd</span> kubeedge </span><br><span class="line"></span><br><span class="line"><span class="comment"># Check out version 1.0.0</span></span><br><span class="line">git checkout v1.0.0 -b dev-v1.0.0</span><br></pre></td></tr></table></figure><blockquote><p>I’ve found many issues building the code above version 1.0.0, please feel free to test on your own environment and let me know if you may succeed.</p></blockquote><h2 id="Step-2-Try-to-build-the-cloud-part"><a href="#Step-2-Try-to-build-the-cloud-part" class="headerlink" title="Step 2. Try to build the cloud part"></a>Step 2. Try to build the cloud part</h2><p>Following the instructions from the Kubernetes official document, let’s try to build the cloud image.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">make cloudimage</span><br></pre></td></tr></table></figure><p>If everything is working as expected, you will get some message like this:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">Successfully built 5f31402ab1ee</span><br><span class="line">Successfully tagged kubeedge/edgecontroller:v1.0.0</span><br></pre></td></tr></table></figure><p>However, if you take that image to deploy on the cloud server, you may get lots of trouble. In my next post, I’ll lead you through several pitfalls I encountered when I was trying to deploy it, but for now, let’s continue on our investigation on how to connect the running container to our IDE for debugging/code review.</p><h2 id="Step-3-Rebuild-the-cloudimage"><a href="#Step-3-Rebuild-the-cloudimage" class="headerlink" title="Step 3. Rebuild the cloudimage"></a>Step 3. Rebuild the cloudimage</h2><p>For the development and code review, I continue to use GoLand IDE (2019.3). The following debugging strategy is mainly inspired by this <span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmpldGJyYWlucy5jb20vZ28vMjAxOC8wNC8zMC9kZWJ1Z2dpbmctY29udGFpbmVyaXplZC1nby1hcHBsaWNhdGlvbnMv" title="https://blog.jetbrains.com/go/2018/04/30/debugging-containerized-go-applications/">post<i class="fa fa-external-link"></i></span>.</p><p>First, locate the Dockerfile in the <code>build/cloud</code> path, and replace its content with following:</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> golang:<span class="number">1.12</span>.<span class="number">1</span>-alpine3.<span class="number">9</span> AS builder</span><br><span class="line"></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> . /go/src/github.com/kubeedge/kubeedge</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># RUN CGO_ENABLED=0 go build -v -o /usr/local/bin/edgecontroller -ldflags="-w -s" \</span></span><br><span class="line"><span class="comment"># github.com/kubeedge/kubeedge/cloud/cmd</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> CGO_ENABLED=0 go build -gcflags <span class="string">"all=-N -l"</span> -v -o /usr/<span class="built_in">local</span>/bin/edgecontroller  \</span></span><br><span class="line"><span class="bash">github.com/kubeedge/kubeedge/cloud/cmd</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Compile Delve</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> apk add --no-cache git</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> go get github.com/derekparker/delve/cmd/dlv</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">FROM</span> alpine:<span class="number">3.9</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># For debug</span></span><br><span class="line"><span class="keyword">EXPOSE</span> <span class="number">2345</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">ENV</span> GOARCHAIUS_CONFIG_PATH /etc/kubeedge/cloud</span><br><span class="line"></span><br><span class="line"><span class="comment"># Allow delve to run on Alpine based containers.</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> apk add --no-cache libc6-compat</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">VOLUME</span><span class="bash"> [<span class="string">"/etc/kubeedge/certs"</span>, <span class="string">"/etc/kubeedge/cloud/conf"</span>]</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> --from=builder /usr/<span class="built_in">local</span>/bin/edgecontroller /usr/<span class="built_in">local</span>/bin/edgecontroller</span></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> --from=builder /go/bin/dlv /</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">ENTRYPOINT</span><span class="bash"> [<span class="string">"/dlv"</span>, <span class="string">"--listen=:2345"</span>, <span class="string">"--headless=true"</span>, <span class="string">"--api-version=2"</span>, <span class="string">"exec"</span>, <span class="string">"/usr/local/bin/edgecontroller"</span>]</span></span><br></pre></td></tr></table></figure><p>Then rebuild the cloudimage from the source project root and save that new image to your docker hub. If you may prefer to skip this step, feel free to grab mine from here <code>r5by/kubeedge_edgecontroller_debug:v1.0.0</code>.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cd to your project root and rebuild the cloud image</span></span><br><span class="line">build cloudimage</span><br><span class="line"></span><br><span class="line"><span class="comment"># login to your docker accnt and save the image</span></span><br><span class="line">docker login -u &lt;user_name&gt;</span><br><span class="line">docker tag kubeedge/edgecontroller:v1.0.0 &lt;user_name&gt;/kubeedge_edgecontroller_debug:v1.0.0</span><br><span class="line">docker push &lt;user_name&gt;/kubeedge_edgecontroller_debug:v1.0.0</span><br></pre></td></tr></table></figure><h2 id="Step-4-Connect-with-the-debugger"><a href="#Step-4-Connect-with-the-debugger" class="headerlink" title="Step 4. Connect with the debugger"></a>Step 4. Connect with the debugger</h2><p>The final step is to connect our IDE debugging tool with the container after deployment. First <code>cd build/cloud</code> then modify your <code>07-deployment.yaml</code> as following:</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line"><span class="attr">    k8s-app:</span> <span class="string">kubeedge</span></span><br><span class="line"><span class="attr">    kubeedge:</span> <span class="string">edgecontroller</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">edgecontroller</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">kubeedge</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    matchLabels:</span></span><br><span class="line"><span class="attr">      k8s-app:</span> <span class="string">kubeedge</span></span><br><span class="line"><span class="attr">      kubeedge:</span> <span class="string">edgecontroller</span></span><br><span class="line"><span class="attr">  template:</span></span><br><span class="line"><span class="attr">    metadata:</span></span><br><span class="line"><span class="attr">      annotations:</span></span><br><span class="line">        <span class="string">container.apparmor.security.beta.kubernetes.io/edgecontroller:</span> <span class="string">unconfined</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        k8s-app:</span> <span class="string">kubeedge</span></span><br><span class="line"><span class="attr">        kubeedge:</span> <span class="string">edgecontroller</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      initContainers:</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">kubeconfig</span></span><br><span class="line"><span class="attr">        image:</span> <span class="attr">alpine:3.9</span></span><br><span class="line"><span class="attr">        volumeMounts:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">kubeconfig</span></span><br><span class="line"><span class="attr">          mountPath:</span> <span class="string">/etc/kubeedge/cloud</span></span><br><span class="line"><span class="attr">        args:</span></span><br><span class="line"><span class="bullet">        -</span> <span class="string">/bin/sh</span></span><br><span class="line"><span class="bullet">        -</span> <span class="bullet">-c</span></span><br><span class="line"><span class="bullet">        -</span> <span class="string">|</span></span><br><span class="line"><span class="string">          apk --update add --no-cache coreutils &amp;&amp; cat | tee /etc/kubeedge/cloud/kubeconfig.yaml &lt;&lt;EOF</span></span><br><span class="line"><span class="string"></span><span class="attr">          apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">          kind:</span> <span class="string">Config</span></span><br><span class="line"><span class="attr">          clusters:</span></span><br><span class="line"><span class="attr">          - name:</span> <span class="string">kubeedge</span></span><br><span class="line"><span class="attr">                      cluster:</span></span><br><span class="line"><span class="attr">              certificate-authority-data:</span> <span class="string">$(cat</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount/ca.crt</span> <span class="string">| base64 -w 0)</span></span><br><span class="line"><span class="string"></span><span class="attr">          users:</span></span><br><span class="line"><span class="attr">          - name:</span> <span class="string">kubeedge</span></span><br><span class="line"><span class="attr">            user:</span></span><br><span class="line"><span class="attr">              token:</span> <span class="string">$(cat</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount/token)</span></span><br><span class="line"><span class="attr">          contexts:</span></span><br><span class="line"><span class="attr">          - name:</span> <span class="string">kubeedge</span></span><br><span class="line"><span class="attr">            context:</span></span><br><span class="line"><span class="attr">              cluster:</span> <span class="string">kubeedge</span></span><br><span class="line"><span class="attr">              user:</span> <span class="string">kubeedge</span></span><br><span class="line"><span class="attr">          current-context:</span> <span class="string">kubeedge</span></span><br><span class="line">          <span class="string">EOF</span></span><br><span class="line"><span class="attr">      containers:</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">edgecontroller</span></span><br><span class="line"><span class="attr">        image:</span> <span class="string">r5by/kubeedge_edgecontroller:v1.0.0</span></span><br><span class="line"><span class="attr">        securityContext:</span></span><br><span class="line"><span class="attr">          capabilities:</span></span><br><span class="line"><span class="attr">            add:</span></span><br><span class="line"><span class="bullet">            -</span> <span class="string">SYS_PTRACE</span></span><br><span class="line"><span class="attr">        imagePullPolicy:</span> <span class="string">Always</span></span><br><span class="line"><span class="attr">        ports:</span></span><br><span class="line"><span class="attr">        - containerPort:</span> <span class="number">10000</span></span><br><span class="line"><span class="attr">          name:</span> <span class="string">cloudhub</span></span><br><span class="line"><span class="attr">          protocol:</span> <span class="string">TCP</span></span><br><span class="line"><span class="attr">        resources:</span></span><br><span class="line"><span class="attr">          limits:</span></span><br><span class="line"><span class="attr">            cpu:</span> <span class="number">200</span><span class="string">m</span></span><br><span class="line"><span class="attr">            memory:</span> <span class="number">1</span><span class="string">Gi</span></span><br><span class="line"><span class="attr">          requests:</span></span><br><span class="line"><span class="attr">            cpu:</span> <span class="number">100</span><span class="string">m</span></span><br><span class="line"><span class="attr">            memory:</span> <span class="number">512</span><span class="string">Mi</span></span><br><span class="line"><span class="attr">        volumeMounts:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">conf</span></span><br><span class="line"><span class="attr">          mountPath:</span> <span class="string">/etc/kubeedge/cloud/conf</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">certs</span></span><br><span class="line"><span class="attr">          mountPath:</span> <span class="string">/etc/kubeedge/certs</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">kubeconfig</span></span><br><span class="line"><span class="attr">          mountPath:</span> <span class="string">/etc/kubeedge/cloud</span></span><br><span class="line"><span class="attr">      restartPolicy:</span> <span class="string">Always</span></span><br><span class="line"><span class="attr">      serviceAccount:</span> <span class="string">edgecontroller</span></span><br><span class="line"><span class="attr">      serviceAccountName:</span> <span class="string">edgecontroller</span></span><br><span class="line"><span class="attr">      volumes:</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">conf</span></span><br><span class="line"><span class="attr">        configMap:</span></span><br><span class="line"><span class="attr">          name:</span> <span class="string">edgecontroller</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">certs</span></span><br><span class="line"><span class="attr">        secret:</span></span><br><span class="line"><span class="attr">          secretName:</span> <span class="string">edgecontroller</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">kubeconfig</span></span><br><span class="line"><span class="attr">        emptyDir:</span> <span class="string">&#123;&#125;</span></span><br></pre></td></tr></table></figure><p>Then create (if not existing) a <code>08-service.yaml</code> file and copy-paste the following content to it:</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">edgecontroller</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">kubeedge</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line"><span class="attr">    k8s-app:</span> <span class="string">kubeedge</span></span><br><span class="line"><span class="attr">    kubeedge:</span> <span class="string">edgecontroller</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  type:</span> <span class="string">NodePort</span></span><br><span class="line"><span class="attr">  ports:</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">cloudhub</span></span><br><span class="line"><span class="attr">    port:</span> <span class="number">10000</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">debug</span></span><br><span class="line"><span class="attr">    port:</span> <span class="number">2345</span></span><br><span class="line"><span class="attr">    nodePort:</span> <span class="number">32345</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    k8s-app:</span> <span class="string">kubeedge</span></span><br><span class="line"><span class="attr">    kubeedge:</span> <span class="string">edgecontroller</span></span><br></pre></td></tr></table></figure><p>Edit a shell script as following within <code>build/cloud</code> and execute it:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> resource <span class="keyword">in</span> $(ls *.yaml)</span><br><span class="line">    <span class="keyword">do</span> k3s kubectl create -f <span class="variable">$resource</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure><blockquote><p><strong>Note</strong>: To use this script, you need to have a k3s master configured properly and secrets files generated. If you are not sure how to do so, please refer to my next post on how to deploy the Kubeedge cloud core then come back to follow the rest.</p></blockquote><p>Verify the edgecontroller service’s up with the following commands:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">k3s kubectl get pod -n kubeedge</span><br><span class="line"><span class="comment"># Output:</span></span><br><span class="line"><span class="comment"># NAME                              READY   STATUS    RESTARTS   AGE</span></span><br><span class="line"><span class="comment"># edgecontroller-85cdc9cf8f-2p8mj   1/1     Running   0          11s</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Check its log</span></span><br><span class="line">k3s kubectl logs edgecontroller-85cdc9cf8f-2p8mj -n kubeedge -c edgecontroller</span><br><span class="line"><span class="comment"># Output:</span></span><br><span class="line"><span class="comment"># API server listening at: [::]:2345</span></span><br></pre></td></tr></table></figure><p>Now configure your IDE as following:</p><p><img src="https://drive.google.com/uc?export=view&id=1pScAXizLDmS6-K8EgqNnsrPt2kpQlo_t" alt="image"></p><p>Click the debug button and start code walking:</p><p><img src="https://drive.google.com/uc?export=view&id=1f81SmNSQOf96pMF4DYajHNvp0TN_Plea" alt="image"></p><h2 id="Step-5-Trouble-Shooting"><a href="#Step-5-Trouble-Shooting" class="headerlink" title="Step 5. Trouble Shooting"></a>Step 5. Trouble Shooting</h2><p>It is likely that you may confront several errors until successfully connect your debugger to the container. If that happens, check the following tips to see whether it may help you out:</p><blockquote><p>1) The pod was failed due to some “CrushLoopBackOff” status or stuck at “Initializing” </p></blockquote><p>Check your CoreDNS service first, it’s likely that it’s not working so the pulling from public repository failed or stuck. Using the following commands to check:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 'kc' alias 'k3s kubectl'</span></span><br><span class="line"><span class="comment"># Verify your coredns is up&amp;running</span></span><br><span class="line">kc get pod --all-namespaces</span><br><span class="line"></span><br><span class="line"><span class="comment"># Test your dns resolver</span></span><br><span class="line">kc run -i --tty busybox --image=busybox --restart=Never -- sh</span><br><span class="line"><span class="comment"># Within the busybox</span></span><br><span class="line">vi /etc/resolv.conf <span class="comment">#nameserver, etc.</span></span><br><span class="line">nslookup www.google.com <span class="comment">#nslookup test</span></span><br><span class="line"><span class="comment"># You should be able to see the server and address listed, if not, use the following commands to:</span></span><br><span class="line"><span class="comment"># 1) Verify each Chain of the iptable is set at "ACCEPT" flag</span></span><br><span class="line">iptables -L | grep INPUT  <span class="comment"># check respectively INPUT/OUTPUT/FORWARD in your iptable</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2) If the above check passed, flush the iptables with following commands to see if error messages are gone</span></span><br><span class="line">iptables --flush</span><br><span class="line">iptables -tnat --flush</span><br><span class="line"></span><br><span class="line"><span class="comment"># If solved, delete the busybox</span></span><br><span class="line">kc delete pod busybox</span><br></pre></td></tr></table></figure><blockquote><p>2) If you see more errors, please refer to my next post on setting up kubeedge cloud part to see if they may be gone. Some errors may be caused by incorrect configurations/running environment.</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;span class=&quot;exturl&quot; data-url=&quot;aHR0cHM6Ly9naXRodWIuY29tL2t1YmVlZGdlL2t1YmVlZGdl&quot; title=&quot;https://github.com/kubeedge/kubeedge&quot;&gt;Kubeedge&lt;i 
      
    
    </summary>
    
    
      <category term="edge computing, cloud computing" scheme="https://ruby-.github.io/categories/edge-computing-cloud-computing/"/>
    
    
      <category term="kubeedge, k3s" scheme="https://ruby-.github.io/tags/kubeedge-k3s/"/>
    
  </entry>
  
  <entry>
    <title>k3s Dev (2) Vagrant + VirtualBox Dev.</title>
    <link href="https://ruby-.github.io/2019/10/30/k3s-dev-2/"/>
    <id>https://ruby-.github.io/2019/10/30/k3s-dev-2/</id>
    <published>2019-10-30T06:19:14.000Z</published>
    <updated>2019-10-30T22:34:09.000Z</updated>
    
    <content type="html"><![CDATA[<p>This post aims to help you gain a better development experience with rancher/k3s project. As an old Chinese saying implies: “A logger should always sharpen his axe before going to do his job” (工欲善其事，必先利其器). So in what follows, you may gain experiences on:</p><ul><li>Adopt k3s’s Vagrantfile to launch our virtual dev environment</li><li>Attach the dlv process and start debugging</li></ul><blockquote><p>Special thanks to Eric@RancherLabs who helps me to get to know about his graceful solution on this. Please follow this portal to admire his other works of art: <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2VyaWt3aWxzb24/dGFiPXJlcG9zaXRvcmllcw==" title="https://github.com/erikwilson?tab=repositories">大神の傳送門<i class="fa fa-external-link"></i></span>.</p></blockquote><h2 id="1-Use-Vagrant"><a href="#1-Use-Vagrant" class="headerlink" title="1. Use Vagrant"></a>1. Use Vagrant</h2><p><span class="exturl" data-url="aHR0cHM6Ly93d3cudmFncmFudHVwLmNvbS8=" title="https://www.vagrantup.com/">Vagrant<i class="fa fa-external-link"></i></span> is not something new but I thought before that it was merely a VM management tool thus overlooked at this technique due to my ignorance. Until now I realize it’s extremely useful for working at an open-source project, or other similar projects that requires people from different locations to work collaboratively. This is because it offers the developer a method to “ship” his/her working environment directly to all other co-workers, in other words, this concept of “virtual dev env” enables consistency among all developers working at the same project.</p><blockquote><p>The idea of Vagrant is quite similar to Docker, for both provides certain degree of “consistency” and “isolation” in my opinion. However, they are built on top of different tech stacks (virtualization vs. container) and each has its own use-case scenario. Eric also pointed out that “Dapper is nice for building &amp; ci but kind of a pain for development”.</p></blockquote><p>To install Vagrant on MacOS, I recommend homebrew, simply issue the following commends in your terminal:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">brew install vagrant</span><br><span class="line"><span class="comment"># or `brew cask install vagrant`</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Check available commands</span></span><br><span class="line">vagrant -h</span><br></pre></td></tr></table></figure><p>The following list shows some commonly used commends in my case:</p><ul><li><code>vagrant up</code>: spin up the boxes;</li><li><code>vagrant status</code>: check the status of the vagrant machine;</li><li><code>vagrant ssh</code>: ssh into the running machine;</li><li><code>vagrant halt</code>: shutdown the running boxes;</li><li><code>vagrant destroy</code>: delete all associated files to your configured vagrant machines.</li></ul><blockquote><ul><li>(1) Vagrant supports other VM softwares all cross platforms, for me I continue to use VirtualBox here since it’s free and I have had already certain experience with it.</li><li>(2) Issue the <code>destroy</code> command will remove the files for your virtual machine saved in your VirtualBox’s settings, i.e. “/yourpathto/VirtualBox VMS/xxx”.</li></ul></blockquote><p>After learning about the basics, let’s take a look at the Vagrantfile in the k3s project root, to see what does:</p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line">BOX = <span class="string">"generic/alpine310"</span></span><br><span class="line">HOME = File.dirname(__FILE_<span class="number">_</span>)</span><br><span class="line">PROJECT = File.basename(HOME)</span><br><span class="line">MOUNT_TYPE = ENV[<span class="string">'MOUNT_TYPE'</span>] <span class="params">||</span> <span class="string">"nfs"</span></span><br><span class="line">NUM_NODES = (ENV[<span class="string">'NUM_NODES'</span>] <span class="params">||</span> <span class="number">0</span>).to_i</span><br><span class="line">NODE_CPUS = (ENV[<span class="string">'NODE_CPUS'</span>] <span class="params">||</span> <span class="number">4</span>).to_i</span><br><span class="line">NODE_MEMORY = (ENV[<span class="string">'NODE_MEMORY'</span>] <span class="params">||</span> <span class="number">8192</span>).to_i</span><br><span class="line">NETWORK_PREFIX = ENV[<span class="string">'NETWORK_PREFIX'</span>] <span class="params">||</span> <span class="string">"10.135.135"</span></span><br><span class="line">VAGRANT_PROVISION = ENV[<span class="string">'VAGRANT_PROVISION'</span>] <span class="params">||</span> <span class="string">"./scripts/vagrant-provision"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># --- Rules for /etc/sudoers to avoid password entry configuring NFS:</span></span><br><span class="line"><span class="comment"># %adminALL = (root) NOPASSWD: /usr/bin/sed -E -e * -ibak /etc/exports</span></span><br><span class="line"><span class="comment"># %adminALL = (root) NOPASSWD: /usr/bin/tee -a /etc/exports</span></span><br><span class="line"><span class="comment"># %adminALL = (root) NOPASSWD: /sbin/nfsd restart</span></span><br><span class="line"><span class="comment"># --- May need to add terminal to System Preferences -&gt; Security &amp; Privacy -&gt; Privacy -&gt; Full Disk Access</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># --- Check for missing plugins</span></span><br><span class="line">required_plugins = <span class="string">%w( vagrant-alpine vagrant-timezone )</span></span><br><span class="line">plugin_installed = <span class="literal">false</span></span><br><span class="line">required_plugins.each <span class="keyword">do</span> <span class="params">|plugin|</span></span><br><span class="line">  <span class="keyword">unless</span> Vagrant.has_plugin?(plugin)</span><br><span class="line">    system <span class="string">"vagrant plugin install <span class="subst">#&#123;plugin&#125;</span>"</span></span><br><span class="line">    plugin_installed = <span class="literal">true</span></span><br><span class="line">  <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="comment"># --- If new plugins installed, restart Vagrant process</span></span><br><span class="line"><span class="keyword">if</span> plugin_installed === <span class="literal">true</span></span><br><span class="line">  exec <span class="string">"vagrant <span class="subst">#&#123;ARGV.join<span class="string">' '</span>&#125;</span>"</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">provision = &lt;&lt;SCRIPT</span><br><span class="line"><span class="comment"># --- Use system gopath if available</span></span><br><span class="line">export GOPATH=<span class="comment">#&#123;ENV['GOPATH']&#125;</span></span><br><span class="line"><span class="comment"># --- Default to root user for vagrant ssh</span></span><br><span class="line">cat &lt;&lt;\\EOF &gt;<span class="regexp">/etc/profile</span>.d/root.sh</span><br><span class="line">[ $EUID -ne <span class="number">0</span> ] &amp;&amp; exec sudo -i</span><br><span class="line">EOF</span><br><span class="line"><span class="comment"># --- Set home to current directory</span></span><br><span class="line">cat &lt;&lt;\\EOF &gt;<span class="regexp">/etc/profile</span>.d/home.sh</span><br><span class="line">export HOME=<span class="string">"<span class="subst">#&#123;HOME&#125;</span>"</span> &amp;&amp; cd</span><br><span class="line">EOF</span><br><span class="line">. /etc/profile.d/home.sh</span><br><span class="line"><span class="comment"># --- Run vagrant provision script if available</span></span><br><span class="line"><span class="keyword">if</span> [ ! -x <span class="comment">#&#123;VAGRANT_PROVISION&#125; ]; then</span></span><br><span class="line">  echo <span class="string">'WARNING: Unable to execute provision script "<span class="subst">#&#123;VAGRANT_PROVISION&#125;</span>"'</span></span><br><span class="line">  exit</span><br><span class="line">fi</span><br><span class="line">echo <span class="string">"running '<span class="subst">#&#123;VAGRANT_PROVISION&#125;</span>'..."</span> &amp;&amp; \</span><br><span class="line">  <span class="comment">#&#123;VAGRANT_PROVISION&#125; &amp;&amp; \</span></span><br><span class="line">  echo <span class="string">"finished '<span class="subst">#&#123;VAGRANT_PROVISION&#125;</span>'!"</span></span><br><span class="line">SCRIPT</span><br><span class="line"></span><br><span class="line">Vagrant.configure(<span class="string">"2"</span>) <span class="keyword">do</span> <span class="params">|config|</span></span><br><span class="line">  config.vm.provider <span class="string">"virtualbox"</span> <span class="keyword">do</span> <span class="params">|v|</span></span><br><span class="line">    v.cpus = NODE_CPUS</span><br><span class="line">    v.memory = NODE_MEMORY</span><br><span class="line">    v.customize [<span class="string">"modifyvm"</span>, <span class="symbol">:id</span>, <span class="string">"--audio"</span>, <span class="string">"none"</span>]</span><br><span class="line">  <span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">  config.vm.box = BOX</span><br><span class="line">  config.vm.hostname = PROJECT</span><br><span class="line">  config.vm.synced_folder <span class="string">"."</span>, HOME, <span class="symbol">type:</span> MOUNT_TYPE</span><br><span class="line">  config.vm.provision <span class="string">"shell"</span>, <span class="symbol">inline:</span> provision</span><br><span class="line">  config.timezone.value = <span class="symbol">:host</span></span><br><span class="line"></span><br><span class="line">  config.vm.network <span class="string">"private_network"</span>, <span class="symbol">ip:</span> <span class="string">"<span class="subst">#&#123;NETWORK_PREFIX&#125;</span>.100"</span> <span class="keyword">if</span> NUM_NODES==<span class="number">0</span></span><br><span class="line"></span><br><span class="line">  (<span class="number">1</span>..NUM_NODES).each <span class="keyword">do</span> <span class="params">|i|</span></span><br><span class="line">    config.vm.define <span class="string">".<span class="subst">#&#123;i&#125;</span>"</span> <span class="keyword">do</span> <span class="params">|node|</span></span><br><span class="line">      node.vm.network <span class="string">"private_network"</span>, <span class="symbol">ip:</span> <span class="string">"<span class="subst">#&#123;NETWORK_PREFIX&#125;</span>.<span class="subst">#&#123;<span class="number">100</span>+i&#125;</span>"</span></span><br><span class="line">      node.vm.hostname = <span class="string">"<span class="subst">#&#123;PROJECT&#125;</span>-<span class="subst">#&#123;i&#125;</span>"</span></span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">  <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><p>As we can see, mainly what it does is to pull the base box image and then prepare it by evoking the provision script and setting up the network. In particular our case, we need to:</p><ul><li><p>(1) Set up the environment variables to bring up vagrant boxes as we want. For example:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># how many node do we want</span></span><br><span class="line"><span class="built_in">export</span> NUM_NODES=2</span><br><span class="line"></span><br><span class="line"><span class="comment"># how many cpus we have for each node</span></span><br><span class="line"><span class="built_in">export</span> NODE_CPUS=1</span><br><span class="line"></span><br><span class="line"><span class="comment"># Also can be customized include the network, memory, etc.</span></span><br><span class="line"><span class="comment"># Finally launch the boxes with the above configurations</span></span><br><span class="line">vagrant up</span><br><span class="line"></span><br><span class="line"><span class="comment"># Check the running machines</span></span><br><span class="line">vagrant status</span><br><span class="line"></span><br><span class="line"><span class="comment"># Connect to one of the above machines</span></span><br><span class="line">vagrant ssh .1</span><br></pre></td></tr></table></figure></li><li><p>(2) The actually box image that has pulled down and configured is saved at: <code>$HOME/.vagrant.d/boxes</code>.</p></li><li><p>(3) To see what vagrant actually does in the <code>ssh</code> procedure, open another terminal then issue <code>ps aux | grep ssh</code> to verify it, then connect to that node again in another terminal by using that command:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh vagrant@127.0.0.1 -p 2222 -o LogLevel=FATAL -o Compression=yes -o DSAAuthentication=yes -o IdentitiesOnly=yes -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -i /yourpathto/k3s/.vagrant/machines/.1/virtualbox/private_key</span><br></pre></td></tr></table></figure></li></ul><h2 id="2-Debugging"><a href="#2-Debugging" class="headerlink" title="2. Debugging"></a>2. Debugging</h2><p>After admiring vagrant, destroy these existing boxes and re-prepare them for enabling delve debugger by adding just one line to the <code>scripts/vagrant-provision</code> file:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="built_in">set</span> -ve</span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> $(dirname <span class="variable">$0</span>)/..</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="comment"># ---</span></span><br><span class="line">mkdir -p <span class="variable">$&#123;GOPATH&#125;</span>/bin</span><br><span class="line">mkdir -p /go</span><br><span class="line">ln -s <span class="variable">$GOPATH</span>/bin /go/bin</span><br><span class="line">sed <span class="string">':a;N;$!ba;s/\\\n/ /g'</span> &lt;Dockerfile.dapper | grep <span class="string">'^RUN '</span> | sed -e <span class="string">'s/^RUN //'</span> &gt;/tmp/docker-run</span><br><span class="line"><span class="built_in">export</span> BINDIR=/go/bin</span><br><span class="line"><span class="built_in">export</span> GOPATH=/go</span><br><span class="line"><span class="built_in">export</span> HOME=/tmp &amp;&amp; <span class="built_in">cd</span></span><br><span class="line">. /tmp/docker-run</span><br><span class="line"><span class="built_in">cd</span> /go</span><br><span class="line">go get github.com/rancher/trash</span><br><span class="line"><span class="comment"># --- Add one line here to enable delve           &lt;==</span></span><br><span class="line">go get -u github.com/go-delve/delve/cmd/dlv</span><br><span class="line">rm -rf /go</span><br><span class="line"><span class="built_in">cd</span></span><br><span class="line"><span class="comment"># ---</span></span><br><span class="line"></span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>Now ssh into the virtual machine and start debugging as we already learned in the previous post:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># After inspecting the vagrant, close and destroy it</span></span><br><span class="line"><span class="comment"># or stop by `vagrant halt`</span></span><br><span class="line">vagrant destroy</span><br><span class="line"></span><br><span class="line"><span class="comment"># Adding dlv to the provision script then reload the vagrant</span></span><br><span class="line">vagrant reload</span><br><span class="line"></span><br><span class="line"><span class="comment"># Build from the source</span></span><br><span class="line">./scripts/download &amp;&amp; ./scripts/build &amp;&amp; ./scripts/package-cli</span><br><span class="line"></span><br><span class="line"><span class="comment"># Launch dlv</span></span><br><span class="line">dlv --listen=:2345 --headless=<span class="literal">true</span> --api-version=2 --accept-multiclient <span class="built_in">exec</span> dist/artifacts/k3s -- --debug server</span><br></pre></td></tr></table></figure><blockquote><p><strong>Note</strong>: Use <code>netstat</code> you will notice some nfs related daemons, these rpc procedures are critical to maintain the consistency between the host’s source files and those to be built in virtual dev boxes. Also, to kill the dlv debugger simply kill the process from a different terminal. The most enhanced experience (at least for me) is that any modification on the source code in my host will be directly synchronized to the virtual box side via the mount, bravo!</p></blockquote><h2 id="3-Summary"><a href="#3-Summary" class="headerlink" title="3. Summary"></a>3. Summary</h2><p>In this post we have used Vagrant and Virtualbox to set up our dev environment. In my following posts, we’ll continue to dig deeper into k3s’ source code and learn more about it soon.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;This post aims to help you gain a better development experience with rancher/k3s project. As an old Chinese saying implies: “A logger sho
      
    
    </summary>
    
    
      <category term="edge computing" scheme="https://ruby-.github.io/categories/edge-computing/"/>
    
    
      <category term="k3s, k8s" scheme="https://ruby-.github.io/tags/k3s-k8s/"/>
    
  </entry>
  
  <entry>
    <title>k3s Dev (1) Environment Setup</title>
    <link href="https://ruby-.github.io/2019/10/10/k3s-dev-1/"/>
    <id>https://ruby-.github.io/2019/10/10/k3s-dev-1/</id>
    <published>2019-10-10T07:07:36.000Z</published>
    <updated>2019-10-30T22:28:01.000Z</updated>
    
    <content type="html"><![CDATA[<p>This post shows in steps how to set up a dev environment for <strong>k3s</strong> project.</p><h2 id="Step-1-Preparation"><a href="#Step-1-Preparation" class="headerlink" title="Step 1. Preparation"></a>Step 1. Preparation</h2><p>The following list shows my local development environment setup:</p><p>For code review &amp; build purpose:</p><ul><li>OS: Mac OS </li><li>Docker: 18.06.1-ce</li><li>JetBrains GoLand IDE</li><li>golang: 1.12.7</li></ul><p>For testing deploy purpose:</p><ul><li>VirtualBox</li><li>Ubuntu 18.04 Server</li></ul><blockquote><p>Alternatively, one could use EC2 instances as testing deploy environment, in which case may directly to go step 2.</p></blockquote><h3 id="1-1-VirtualBox-Setup"><a href="#1-1-VirtualBox-Setup" class="headerlink" title="1.1 VirtualBox Setup"></a>1.1 VirtualBox Setup</h3><p>Download Ubuntu 18.04 iso from <span class="exturl" data-url="aHR0cDovL3JlbGVhc2VzLnVidW50dS5jb20vMTguMDQv" title="http://releases.ubuntu.com/18.04/">official source<i class="fa fa-external-link"></i></span> and install it on VirtualBox. Configure the network interface as following:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Check all available network adapters</span></span><br><span class="line">ifconfig -a</span><br><span class="line"></span><br><span class="line"><span class="comment"># Then Use netplan to config all interfaces</span></span><br><span class="line">sudo vi /etc/netplan/50-cloud-init.yaml</span><br></pre></td></tr></table></figure><p>Change the content accordingly (192.168.56.1 is my gateway setting, change it according to your own VirtualBox network setting):</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">network:</span></span><br><span class="line"><span class="attr">    ethernets:</span></span><br><span class="line"><span class="attr">        enp0s3:</span></span><br><span class="line"><span class="attr">            addresses:</span> <span class="string">[]</span></span><br><span class="line"><span class="attr">            dhcp4:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">            dhcp6:</span> <span class="literal">no</span></span><br><span class="line"><span class="attr">            optional:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">            nameservers:</span></span><br><span class="line"><span class="attr">               addresses:</span> <span class="string">[8.8.8.8]</span></span><br><span class="line"><span class="attr">        enp0s8:</span></span><br><span class="line"><span class="attr">             addresses:</span> <span class="string">[192.168.56.10/24]</span></span><br><span class="line"><span class="attr">             dhcp4:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">             dhcp6:</span> <span class="literal">no</span></span><br><span class="line"><span class="attr">             optional:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">             routes:</span></span><br><span class="line"><span class="attr">                - to:</span> <span class="number">192.168</span><span class="number">.56</span><span class="number">.1</span><span class="string">/24</span></span><br><span class="line"><span class="attr">                  via:</span> <span class="number">192.168</span><span class="number">.56</span><span class="number">.1</span></span><br><span class="line"><span class="attr">    version:</span> <span class="number">2</span></span><br></pre></td></tr></table></figure><p>Save and apply the changes:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">sudo netplan apply</span><br><span class="line"></span><br><span class="line"><span class="comment"># Test connectivity</span></span><br><span class="line">ping 192.168.56.101 <span class="comment"># another virtual machine</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Test installing k3s</span></span><br><span class="line">curl -sfL https://get.k3s.io | INSTALL_K3S_BIN_DIR=<span class="string">"/home/main/k3s"</span> sh -</span><br></pre></td></tr></table></figure><h3 id="1-2-Golang-Environment"><a href="#1-2-Golang-Environment" class="headerlink" title="1.2 Golang Environment"></a>1.2 Golang Environment</h3><p>For Mac OS users, I recommend use <code>homebrew</code> to manage go environment. However, go has its own version manager called GVM, refer <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL21vb3Z3ZWIvZ3Zt" title="https://github.com/moovweb/gvm">here<i class="fa fa-external-link"></i></span> for detailed information. To use earlier version of go, add following to your <code>.bashrc</code> file:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># homebrew go version config </span></span><br><span class="line"><span class="function"><span class="title">goconfig</span></span>() &#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="string">"<span class="variable">$1</span>"</span> <span class="keyword">in</span></span><br><span class="line">        <span class="string">"1.12"</span>)</span><br><span class="line">            brew switch go 1.12.7</span><br><span class="line">            <span class="built_in">export</span> GOROOT=/usr/<span class="built_in">local</span>/Cellar/go/1.12.7/libexec</span><br><span class="line">            ;;</span><br><span class="line">        <span class="string">"1.13"</span>)</span><br><span class="line">            brew switch go 1.13</span><br><span class="line">            <span class="built_in">export</span> GOROOT=/usr/<span class="built_in">local</span>/Cellar/go/1.13/libexec</span><br><span class="line">            ;;</span><br><span class="line">        *)</span><br><span class="line">            brew switch go 1.12.7</span><br><span class="line">            <span class="built_in">export</span> GOROOT=/usr/<span class="built_in">local</span>/Cellar/go/1.12.7/libexec</span><br><span class="line">            ;;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">esac</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Installed Go path</span></span><br><span class="line">    <span class="built_in">export</span> GOPATH=<span class="variable">$HOME</span>/go</span><br><span class="line">    <span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:GOROOT/bin</span><br><span class="line">    <span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:$(go env GOPATH)/bin</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>To use simply pass the version selected. For example, to change to go version 12:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Switch to go version 12</span></span><br><span class="line">goconfig 1.12</span><br></pre></td></tr></table></figure><h3 id="1-3-Source-Code-Download"><a href="#1-3-Source-Code-Download" class="headerlink" title="1.3 Source Code Download"></a>1.3 Source Code Download</h3><p>With go environment set up, now we go to its workspace to pull the source from github (I have already forked k3s project to my own github account, if that’s not the case for you, simply pull the source from <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3JhbmNoZXIvazNz" title="https://github.com/rancher/k3s">rancher<i class="fa fa-external-link"></i></span>)</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /Users/yourname/go/src/github.com/yourgithubacct</span><br><span class="line"></span><br><span class="line"><span class="comment"># Download my forked project to local</span></span><br><span class="line">git <span class="built_in">clone</span> --depth 1 https://github.com/ruby-/k3s.git</span><br><span class="line"></span><br><span class="line"><span class="comment"># Add rancher remote source</span></span><br><span class="line">git remote add rancher https://github.com/rancher/k3s.git</span><br><span class="line"></span><br><span class="line"><span class="comment"># now there should be two remote sources: origin (my own) and rancher's</span></span><br><span class="line">git remote</span><br><span class="line"></span><br><span class="line"><span class="comment"># fetch from rancher's master branch and merge to local (shouldn't be any change yet)</span></span><br><span class="line">git fetch rancher</span><br><span class="line">git merge rancher/master</span><br></pre></td></tr></table></figure><h2 id="Step-2-Build-amp-Test-Launch"><a href="#Step-2-Build-amp-Test-Launch" class="headerlink" title="Step 2. Build &amp; Test Launch"></a>Step 2. Build &amp; Test Launch</h2><p>Open the k3s folder in GoLand IDE, on Mac OS, press <code>⌘ + ⇧ + f</code> to search in path for <em>“k3s is up and running”</em>, open the <em>pkg/cli/server/server.go</em> file and add following statement:</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">run</span><span class="params">(app *cli.Context, cfg *cmds.Server)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line">    ctx := signals.SetupSignalHandler(context.Background())</span><br><span class="line">    certs, err := server.StartServer(ctx, &amp;serverConfig)</span><br><span class="line">    <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span> err</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">    logrus.Info(<span class="string">"k3s is up and running"</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// Add a new logging info here</span></span><br><span class="line">    logrus.Info(<span class="string">"==================&gt; Fog is just clouds that have fell down! &lt;=================="</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> notifySocket != <span class="string">""</span> &#123;</span><br><span class="line">    os.Setenv(<span class="string">"NOTIFY_SOCKET"</span>, notifySocket)</span><br><span class="line">        systemd.SdNotify(<span class="literal">true</span>, <span class="string">"READY=1\n"</span>)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Now open the terminal within GoLand IDE, then issue <code>make</code> command and wait for it’s pulling required docker images and build the project for us. After the building procedure, there should be <strong>hyperkube</strong>, <strong>k3s</strong> produced in the <em>dist/artifacts/</em> folder. Simply copy <strong>k3s</strong> to your deploy environment for testing purpose (for me only need to copy to virtualbox ubuntu server that has been setup):</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">scp dist/artifacts/k3s main@192.168.56.10:~/k3s/</span><br><span class="line"></span><br><span class="line"><span class="comment"># Start k3s server and verify the added logged info</span></span><br><span class="line">k3s server &gt; server.log 2&gt;&amp;1 &amp;</span><br><span class="line">vi server.log</span><br></pre></td></tr></table></figure><blockquote><p>Note that:</p><ul><li>(1) Remember to <code>chmod 777 k3s_install_path</code> the install path for <code>scp</code> to be able to upload k3s executable; </li><li>(2) k3s doesn’t support cross compile at current release, refer to <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3JhbmNoZXIvazNzL2lzc3Vlcy81MzA=" title="https://github.com/rancher/k3s/issues/530">issue#530<i class="fa fa-external-link"></i></span> for detailed discussion regarding this;</li><li>(3) There are two options for developers to build k3s from source. We are adapting docker method with <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3JhbmNoZXIvZGFwcGVy" title="https://github.com/rancher/dapper">rancher/dapper<i class="fa fa-external-link"></i></span> wrapper in this post. However for those who are working on Linux, may alternatively download the dependencies and directly build the source with <code>go build</code> commend described <span class="exturl" data-url="aHR0cHM6Ly9yYW5jaGVyLmNvbS9kb2NzL2szcy9sYXRlc3QvZW4vYnVpbGRpbmcv" title="https://rancher.com/docs/k3s/latest/en/building/">here<i class="fa fa-external-link"></i></span>; unfortunately this compile option is not available for Mac OS users at current release, refer to <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3JhbmNoZXIvazNzL2lzc3Vlcy8yNzM=" title="https://github.com/rancher/k3s/issues/273">issue#273<i class="fa fa-external-link"></i></span> for detailed discussion regarding this.</li><li>(4) For Mac OS users, docker tends to accumulate its data file (store at <code>/Users/yourname/Library/Containers/com.docker.docker/Data/vms/0/Docker.qcow2</code>) which contains its self os image and downloaded containers. Build <strong>k3s</strong> project may consume ~10GB space on disk and it keeps growing. The way to get around this is to use docker built-in “reset” tab (Also note that <code>docker system prune</code> won’t save you from this pitfall).</li></ul></blockquote><h2 id="Step-3-Breakpoint-amp-debugging"><a href="#Step-3-Breakpoint-amp-debugging" class="headerlink" title="Step 3. Breakpoint &amp; debugging"></a>Step 3. Breakpoint &amp; debugging</h2><p>It is essential for us engineers to be able to set up breakpoint and debug the code in software development. In this section we’ll try to connect to remotely deployed <strong>k3s</strong> executable and use <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2dvLWRlbHZlL2RlbHZl" title="https://github.com/go-delve/delve">delve<i class="fa fa-external-link"></i></span> tool to navigate through the debugging process. </p><h3 id="3-1-Install-go-and-dlv-in-deploy-env"><a href="#3-1-Install-go-and-dlv-in-deploy-env" class="headerlink" title="3.1 Install go and dlv in deploy env"></a>3.1 Install go and dlv in deploy env</h3><p>To install and set up go environment and dlv debugger on Ubuntu 18.04 server VM we created earlier, simply follow these two guides:</p><ul><li><span class="exturl" data-url="aHR0cHM6Ly93d3cuZGlnaXRhbG9jZWFuLmNvbS9jb21tdW5pdHkvdHV0b3JpYWxzL2hvdy10by1pbnN0YWxsLWdvLW9uLXVidW50dS0xOC0wNA==" title="https://www.digitalocean.com/community/tutorials/how-to-install-go-on-ubuntu-18-04">How To Install Go on Ubuntu 18.04<i class="fa fa-external-link"></i></span></li><li><span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2dvLWRlbHZlL2RlbHZlL2Jsb2IvbWFzdGVyL0RvY3VtZW50YXRpb24vaW5zdGFsbGF0aW9uL2xpbnV4L2luc3RhbGwubWQ=" title="https://github.com/go-delve/delve/blob/master/Documentation/installation/linux/install.md">dlv - Installation on Linux<i class="fa fa-external-link"></i></span></li></ul><p>To get familiar with <code>dlv</code> basic workflows and combine it with JetBrain GoLand IDE, I recommend to follow these practices:</p><ul><li><span class="exturl" data-url="aHR0cHM6Ly93d3cuamFtZXNzdHVydGV2YW50LmNvbS9wb3N0cy9Vc2luZy10aGUtR28tRGVsdmUtRGVidWdnZXItZnJvbS10aGUtY29tbWFuZC1saW5lLw==" title="https://www.jamessturtevant.com/posts/Using-the-Go-Delve-Debugger-from-the-command-line/">Using the Go Delve Debugger from the command line<i class="fa fa-external-link"></i></span></li><li><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmpldGJyYWlucy5jb20vZ28vMjAxOS8wMi8wNi9kZWJ1Z2dpbmctd2l0aC1nb2xhbmQtZ2V0dGluZy1zdGFydGVkLw==" title="https://blog.jetbrains.com/go/2019/02/06/debugging-with-goland-getting-started/">Debugging with GoLand – Getting Started<i class="fa fa-external-link"></i></span></li></ul><p>Now let us go back to our <strong>k3s</strong> project, find and modify the following lines in <code>scripts/build.sh</code>:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line"></span><br><span class="line">VERSIONFLAGS=<span class="string">"</span></span><br><span class="line"><span class="string">    -X <span class="variable">$PKG</span>/pkg/version.Version=<span class="variable">$VERSION</span></span></span><br><span class="line"><span class="string">    -X <span class="variable">$PKG</span>/pkg/version.GitCommit=<span class="variable">$&#123;COMMIT:0:8&#125;</span></span></span><br><span class="line"><span class="string">    -X <span class="variable">$PKG</span>/vendor/<span class="variable">$PKG_CONTAINERD</span>/version.Version=<span class="variable">$VERSION_CONTAINERD</span></span></span><br><span class="line"><span class="string">    -X <span class="variable">$PKG</span>/vendor/<span class="variable">$PKG_CONTAINERD</span>/version.Package=<span class="variable">$PKG_RANCHER_CONTAINERD</span></span></span><br><span class="line"><span class="string">    -X <span class="variable">$PKG</span>/vendor/<span class="variable">$PKG_CRICTL</span>/pkg/version.Version=<span class="variable">$VERSION_CRICTL</span>"</span></span><br><span class="line"><span class="comment"># Comment out LDFLAGS (link) for debug: "-w"= wipe out debug info ;; "-s"= remove symbol table</span></span><br><span class="line"><span class="comment"># LDFLAGS="</span></span><br><span class="line"><span class="comment">#    -w -s"</span></span><br><span class="line">LDFLAGS=<span class="string">""</span></span><br><span class="line">STATIC=<span class="string">"</span></span><br><span class="line"><span class="string">    -extldflags '-static'</span></span><br><span class="line"><span class="string">"</span></span><br><span class="line"></span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>Go to <code>scripts/package-cli.sh</code> file and change the following:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line"></span><br><span class="line">go generate</span><br><span class="line">LDFLAGS=<span class="string">"</span></span><br><span class="line"><span class="string">    -X github.com/rancher/k3s/pkg/version.Version=<span class="variable">$VERSION</span></span></span><br><span class="line"><span class="string">    -X github.com/rancher/k3s/pkg/version.GitCommit=<span class="variable">$&#123;COMMIT:0:8&#125;</span></span></span><br><span class="line"><span class="string">    -w -s</span></span><br><span class="line"><span class="string">"</span></span><br><span class="line">STATIC=<span class="string">"-extldflags '-static'"</span></span><br><span class="line"><span class="comment"># CGO_ENABLED=0 go build -ldflags "$LDFLAGS $STATIC" -o $&#123;CMD_NAME&#125; ./cmd/k3s/main.go</span></span><br><span class="line"><span class="comment"># Add gcflags to enable dlv</span></span><br><span class="line">CGO_ENABLED=0 go build -gcflags <span class="string">"all=-N -l"</span> -ldflags <span class="string">"<span class="variable">$STATIC</span>"</span> -o <span class="variable">$&#123;CMD_NAME&#125;</span> ./cmd/k3s/main.go</span><br></pre></td></tr></table></figure><p>Commit the file changes to our local git repo and rebuild the project, then upload the new <strong>k3s</strong> executable to our local VM:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Commit local changes</span></span><br><span class="line">git add .</span><br><span class="line">git commit -m <span class="string">"enable dlv"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Rebuild project</span></span><br><span class="line">make</span><br><span class="line"></span><br><span class="line"><span class="comment"># Upload to deploy</span></span><br><span class="line">scp dist/artifacts/k3s main@192.168.56.10:~/k3s/</span><br><span class="line"></span><br><span class="line"><span class="comment"># Launch with dlv: note `dlv exec xxx -- paras` means passing the parameters after "--" to our executable instead of dlv</span></span><br><span class="line">dlv --listen=:2345 --headless=<span class="literal">true</span> --api-version=2 --accept-multiclient <span class="built_in">exec</span> /home/main/k3s/k3s -- --debug server</span><br></pre></td></tr></table></figure><p>Setup a new go remote debug run/debug configuration in GoLand IDE which looks like this:<br><img src="https://drive.google.com/uc?export=view&id=1VTjvnD_Fi3o1kGt3hc_o-IyeubWb5bTX" alt="image"></p><p>Toggle some breakpoint at main entry then click <strong>debug</strong> button to start debugging.<br><img src="https://drive.google.com/uc?export=view&id=1Yf24i0WFEMJR-mnvyOg79X_xcnqx_06t" alt="image"></p><blockquote><p>Some of my questions:</p><ul><li>(1) <del>Use the <code>make</code> method to build the whole project takes long time (3-5 min for me). I wonder if there’s some “quick” and “convenient” way to speedup this procedure, e.g. build only parts that have been changed? Please leave comments below if you know the answer to this.</del><br>(Updated) Please refer my following post for a better way to separate source code edit &amp; build/test environment here at <a href="/2019/10/30/k3s-dev-2/" title="k3s Dev (2) Vagrant + VirtualBox Dev.">k3s Dev (2) Vagrant + VirtualBox Dev.</a></li><li>(2) The latest stable version of GoLand(2019.2) leave the channel open after the debugging procedure has been stopped within IDE. Simple kill the dlv by PID to get around this issue.</li><li>(3) Run <code>k3s</code> command with generate a bunch of code in <code>/var/lib/rancher/k3s/</code>, these run time generated binaries and configurations contain most important components including <code>k3s-server</code> and <code>k3s-agent</code>. Details about these we’ll explore also in next my post.</li></ul></blockquote><h2 id="Summery"><a href="#Summery" class="headerlink" title="Summery"></a>Summery</h2><p>Learning k3s from source is important for us to contribute to its community. In my next post, I’ll try to investigate its scheduling mechanism and explain the related major workflow.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;This post shows in steps how to set up a dev environment for &lt;strong&gt;k3s&lt;/strong&gt; project.&lt;/p&gt;
&lt;h2 id=&quot;Step-1-Preparation&quot;&gt;&lt;a href=&quot;#Step
      
    
    </summary>
    
    
      <category term="edge computing" scheme="https://ruby-.github.io/categories/edge-computing/"/>
    
    
      <category term="k3s, k8s" scheme="https://ruby-.github.io/tags/k3s-k8s/"/>
    
  </entry>
  
  <entry>
    <title>k3s Basics</title>
    <link href="https://ruby-.github.io/2019/09/29/k3s-basics/"/>
    <id>https://ruby-.github.io/2019/09/29/k3s-basics/</id>
    <published>2019-09-29T09:45:11.000Z</published>
    <updated>2019-10-12T22:09:41.000Z</updated>
    
    <content type="html"><![CDATA[<p>This post explains my first impression with <strong>k3s</strong>.</p><h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><p>In order to work on k3s project, one needs to learn to use it at first. This post summarize the main steps of deploying <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3JhbmNoZXIvazNz" title="https://github.com/rancher/k3s">k3s<i class="fa fa-external-link"></i></span> in our local lab environment and also on AWS EC2.</p><h2 id="Local-k3s-cluster-Setup"><a href="#Local-k3s-cluster-Setup" class="headerlink" title="Local k3s cluster Setup"></a>Local k3s cluster Setup</h2><p>The basic hardware setup for this demo is as the same as the last post on k8s demo (3 VMs), feel free to apply the following methods with the latest released k3s on your own Raspbian nodes, it should work as we also tested it. However, the latest released version (0.9.1 at the time of this post) of k3s has some ca-related issues for an agent to join the master node (if a full ca-enabled Kubernetes cluster has been configured on these nodes), thus an earlier release version (0.2.0) was used for this section.</p><h3 id="Step-1-Stop-the-previously-installed-k8s-related-services-optional"><a href="#Step-1-Stop-the-previously-installed-k8s-related-services-optional" class="headerlink" title="Step 1: Stop the previously installed k8s related services (optional)"></a>Step 1: Stop the previously installed k8s related services (optional)</h3><p>On master node:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">service kube-calico stop</span><br><span class="line">service kube-scheduler stop</span><br><span class="line">service kube-controller-manager stop</span><br><span class="line">service kube-apiserver stop</span><br><span class="line">service etcd stop &amp;&amp; rm -fr /var/lib/etcd/*</span><br></pre></td></tr></table></figure><p>On worker nodes:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">service kubelet stop &amp;&amp; rm -fr /var/lib/kubelet/*</span><br><span class="line">service kube-proxy stop &amp;&amp; rm -fr /var/lib/kube-proxy/*</span><br><span class="line">service kube-calico stop</span><br></pre></td></tr></table></figure><blockquote><p>Here I simply turn k8s off to avoid potential conflicts between k8s and k3s deployment. However this doesn’t prevent the ca issue for latest k3s releases (&gt;v0.2.0) to work with previously installed k8s environment.</p></blockquote><h3 id="Step-2-Deploy-k3s-on-each-node"><a href="#Step-2-Deploy-k3s-on-each-node" class="headerlink" title="Step 2: Deploy k3s on each node"></a>Step 2: Deploy k3s on each node</h3><p>To install k3s is quite simple, we will use the following commands install and start k3s on master and two worker machines separately. </p><p>On master node:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Install k3s with rancher script</span></span><br><span class="line"><span class="comment"># The script download the binaries, pull the images (containerd) and enable/start the k3s-related systemctl services</span></span><br><span class="line">mkdir k3s</span><br><span class="line"></span><br><span class="line"><span class="comment"># With INSTALL_K3S_EXEC="--disable-agent" option, one may launch k3s server on the node without an agent (which may cause some issues with current release of k3s)</span></span><br><span class="line">curl -sfL https://get.k3s.io | INSTALL_K3S_BIN_DIR=<span class="string">"/home/main/k3s"</span> INSTALL_K3S_VERSION=<span class="string">"v0.2.0"</span>  sh -</span><br><span class="line"></span><br><span class="line"><span class="comment"># Verify the k3s system services are listening on their ports</span></span><br><span class="line">netstat -nltp</span><br><span class="line"></span><br><span class="line"><span class="comment"># Verify the k3s cluster status</span></span><br><span class="line">systemctl status k3s</span><br></pre></td></tr></table></figure><blockquote><p>On master node, one should see services and their port numbers: <em>k3s : 6443/6444, 10251/10252</em></p></blockquote><p>After installation, the k3s binary folder looks like this:</p><figure class="highlight console"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">.</span><br><span class="line">├── crictl -&gt; k3s</span><br><span class="line">├── k3s</span><br><span class="line">├── k3s-killall.sh</span><br><span class="line">└── k3s-uninstall.sh</span><br></pre></td></tr></table></figure><blockquote><p>With out the INSTALL_K3S_BIN_DIR option, k3s will be installed at /usr/local/bin</p></blockquote><p>Now, in order to join new workers to this master node, one needs first grab the token on that (master) node:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Example output: K10af00f60b1fa01b0a413e78922fd79efad2528bc4b0d19a357b5e2650d84252c5::node:f06ab2ff7068846d6b18b342f5f6a1bb</span></span><br><span class="line">cat /var/lib/rancher/k3s/server/node-token</span><br></pre></td></tr></table></figure><p>On worker nodes:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mkdir k3s</span><br><span class="line"></span><br><span class="line"><span class="comment"># download &amp; active the k3s-agent service</span></span><br><span class="line">curl -sfL https://get.k3s.io | INSTALL_K3S_BIN_DIR=<span class="string">"/home/main/k3s"</span> INSTALL_K3S_VERSION=<span class="string">"v0.2.0"</span> K3S_TOKEN=<span class="string">"K10af00f60b1fa01b0a413e78922fd79efad2528bc4b0d19a357b5e2650d84252c5::node:f06ab2ff7068846d6b18b342f5f6a1bb"</span> K3S_URL=<span class="string">"https://192.168.56.103:6443"</span> sh -</span><br><span class="line"></span><br><span class="line"><span class="comment"># check the service status</span></span><br><span class="line">systemctl status k3s-agent</span><br></pre></td></tr></table></figure><p>The installation of k3s agent on worker nodes looks like this:</p><figure class="highlight console"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">.</span><br><span class="line">├── crictl -&gt; k3s</span><br><span class="line">├── k3s</span><br><span class="line">├── k3s-agent-uninstall.sh</span><br><span class="line">└── k3s-killall.sh</span><br></pre></td></tr></table></figure><blockquote><p>On worker node, k3s has services and ports: <em>k3s : 42323, containerd : 10010</em></p></blockquote><p>Now on the master node, one should be able to verify the newly added cluster resources:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## Now verify the newly added worker in the cluster</span></span><br><span class="line">k3s kubectl get nodes</span><br><span class="line"></span><br><span class="line"><span class="comment">## Do some deployment here...</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## Clean-up</span></span><br><span class="line"><span class="comment"># Kill k3s services after inspection (on each node)</span></span><br><span class="line">k3s-killall.sh</span><br><span class="line"></span><br><span class="line"><span class="comment"># Uninstall k3s on master</span></span><br><span class="line">k3s-uninstall.sh</span><br><span class="line"><span class="comment"># Uninstall k3s on worker nodes</span></span><br><span class="line">k3s-agent-uninstall.sh</span><br></pre></td></tr></table></figure><h2 id="Install-k3s-manually-on-EC2-instances"><a href="#Install-k3s-manually-on-EC2-instances" class="headerlink" title="Install k3s manually on EC2 instances"></a>Install k3s manually on EC2 instances</h2><p>This section explains how to manually download k3s binaries from rancher’s official release and cluster-up. Here we use AWS EC2 service as following configuration:</p><table><thead><tr><th align="center">Instance OS</th><th align="center">Arch</th><th align="center">IP (internal)</th><th align="center">Instance Type</th><th align="center">vCPU</th><th align="center">Memory</th><th align="center">Node Role</th></tr></thead><tbody><tr><td align="center">Ubuntu Server 18.04 LTS (HVM), SSD Volume Type</td><td align="center">amd64(x86_64)</td><td align="center">172.31.46.70</td><td align="center">t2.medium</td><td align="center">2</td><td align="center">4GiB</td><td align="center">master</td></tr><tr><td align="center">Amazon Linux 2 AMI (HVM), SSD Volume Type</td><td align="center">arm64(aarch64)</td><td align="center">172.31.36.129</td><td align="center">a1.medium</td><td align="center">1</td><td align="center">2GiB</td><td align="center">worker</td></tr></tbody></table><blockquote><p>Remember to allow all traffic from anywhere in your security group setting.</p></blockquote><p>First, let us <code>ssh</code> to each running instance and prepare the k3s executable</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Change to your own pem key file and instance address:</span></span><br><span class="line">ssh -i ~/.ssh/your-key.pem ubuntu@ec2-x-x-x-x.region.compute.amazonaws.com</span><br><span class="line"></span><br><span class="line"><span class="comment"># Prepare download folder</span></span><br><span class="line">mkdir k3s</span><br><span class="line"><span class="built_in">cd</span> k3s</span><br><span class="line"></span><br><span class="line"><span class="comment">## Download the desired release version from: https://github.com/rancher/k3s/releases?after=v0.10.0-alpha1</span></span><br><span class="line"><span class="comment"># On master (x86_64)</span></span><br><span class="line">wget https://github.com/rancher/k3s/releases/download/v0.9.1/k3s</span><br><span class="line"><span class="comment"># On worker (arm)</span></span><br><span class="line">wget https://github.com/rancher/k3s/releases/download/v0.9.1/k3s-arm64</span><br><span class="line">mv k3s-arm64 k3s</span><br><span class="line"></span><br><span class="line"><span class="comment"># Add exec mode</span></span><br><span class="line">chmod +x k3s</span><br></pre></td></tr></table></figure><p>On master node:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Start k3s server</span></span><br><span class="line">./k3s server &gt; server.log 2&gt;&amp;1 &amp;</span><br><span class="line"></span><br><span class="line"><span class="comment"># Get token copy-and-paste the output to your worker:</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"export node_token=<span class="variable">$(cat /var/lib/rancher/k3s/server/node-token)</span>"</span></span><br></pre></td></tr></table></figure><p>On worker node:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># copy-and-paste token from master here</span></span><br><span class="line"><span class="built_in">export</span> node_token=...</span><br><span class="line"></span><br><span class="line"><span class="comment"># Start agent, pass server url and token</span></span><br><span class="line">./k3s agent --server https://172.31.46.70:6443 --token <span class="string">"<span class="variable">$node_token</span>"</span> &gt;&amp; k3s-agent.log &amp;</span><br></pre></td></tr></table></figure><p>After a little while, check the cluster info with <code>k3s kubectl</code> command described in last section on the master node.</p><blockquote><p>Simply kill the PID to stop k3s or k3s-agent in the demo to shut down the cluster after inspection.</p></blockquote><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>Ranger k3s is much smaller and easier to deploy compared to Kubernetes, and it requires less effort and resources to set up. In next post, we will discuss how to set-up a development environment on k3s and dive deeper to learn k3s from its source code.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;This post explains my first impression with &lt;strong&gt;k3s&lt;/strong&gt;.&lt;/p&gt;
&lt;h2 id=&quot;Motivation&quot;&gt;&lt;a href=&quot;#Motivation&quot; class=&quot;headerlink&quot; title=
      
    
    </summary>
    
    
      <category term="edge computing" scheme="https://ruby-.github.io/categories/edge-computing/"/>
    
    
      <category term="k3s, k8s" scheme="https://ruby-.github.io/tags/k3s-k8s/"/>
    
  </entry>
  
  <entry>
    <title>k8s Basics</title>
    <link href="https://ruby-.github.io/2019/09/17/k8s-basics/"/>
    <id>https://ruby-.github.io/2019/09/17/k8s-basics/</id>
    <published>2019-09-17T12:56:46.000Z</published>
    <updated>2019-10-12T22:10:19.000Z</updated>
    
    <content type="html"><![CDATA[<p>This post demonstrate some Kubernetes basic commends.</p><h2 id="Server-Overview"><a href="#Server-Overview" class="headerlink" title="Server Overview"></a>Server Overview</h2><p>We have setup 3 virtual machines，each has 1 cpu and 1GB memory. Details：</p><table><thead><tr><th align="center">Server OS</th><th align="center">IP Address</th><th align="center">Node Type</th><th align="center">CPU</th><th align="center">Memory</th><th align="center">Hostname</th></tr></thead><tbody><tr><td align="center">ubuntu16.04</td><td align="center">192.168.56.103</td><td align="center">master</td><td align="center">1</td><td align="center">1G</td><td align="center">server01</td></tr><tr><td align="center">ubuntu16.04</td><td align="center">192.168.56.104</td><td align="center">slave1</td><td align="center">1</td><td align="center">1G</td><td align="center">server02</td></tr><tr><td align="center">ubuntu16.04</td><td align="center">192.168.56.105</td><td align="center">slave2</td><td align="center">1</td><td align="center">1G</td><td align="center">server03</td></tr></tbody></table><blockquote><p>To follow this demo, root privilege is required, ask system admin (Todd) for root access.</p></blockquote><a id="more"></a><h2 id="Startup-all-nodes"><a href="#Startup-all-nodes" class="headerlink" title="Startup all nodes"></a>Startup all nodes</h2><p>Login to the system then start virtualBox and each virtual machine.</p><h3 id="Launch-VirtualBox"><a href="#Launch-VirtualBox" class="headerlink" title="Launch VirtualBox"></a>Launch VirtualBox</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># get root privilege</span></span><br><span class="line">$ sudo -s</span><br><span class="line"><span class="comment"># Then start master, slave1 and slave2 virtual machines </span></span><br><span class="line">$ virtualbox</span><br></pre></td></tr></table></figure><h3 id="Login-to-each-node"><a href="#Login-to-each-node" class="headerlink" title="Login to each node"></a>Login to each node</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ Login as: main</span><br><span class="line"><span class="comment"># passwd: 000000</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># And get root priviledge on each node</span></span><br><span class="line">$ sudo -s</span><br></pre></td></tr></table></figure><h3 id="Check-system-information-on-each-node"><a href="#Check-system-information-on-each-node" class="headerlink" title="Check system information on each node"></a>Check system information on each node</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># check ip address</span></span><br><span class="line">$ ifconfig</span><br><span class="line"><span class="comment"># check running containers</span></span><br><span class="line">$ docker ps</span><br><span class="line"><span class="comment"># check services &amp; ports</span></span><br><span class="line">$ netstat -nltp</span><br></pre></td></tr></table></figure><blockquote><p>On master node, one should see services and their port numbers: <em>kube-apiserver : 6443/8080, etcd : 2379/2380, kube-scheduler : 10251, kube-controller : 10252, calico-felix : 9099</em></p></blockquote><blockquote><p>On worker nodes, one should see services and their port numbers: <em>kubelet : 4194/10248/10250/10255, kube-proxy:10249/10256, calico-felix : 9099</em></p></blockquote><h2 id="Commonly-used-commands"><a href="#Commonly-used-commands" class="headerlink" title="Commonly used commands"></a>Commonly used commands</h2><h3 id="Use-calico-to-check-the-network-status-on-each-node"><a href="#Use-calico-to-check-the-network-status-on-each-node" class="headerlink" title="Use calico to check the network status on each node"></a>Use calico to check the network status on each node</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ calicoctl node status</span><br></pre></td></tr></table></figure><blockquote><p>At each node, it should be able to see the other two nodes’ ip addresses in the cluster.</p></blockquote><h3 id="Use-kubectl-on-master-node-to-verify-the-cluster-resources-deloyment-nodes-pods-services-etc"><a href="#Use-kubectl-on-master-node-to-verify-the-cluster-resources-deloyment-nodes-pods-services-etc" class="headerlink" title="Use kubectl on master node to verify the cluster resources (deloyment, nodes, pods, services, etc.)"></a>Use kubectl on master node to verify the cluster resources (deloyment, nodes, pods, services, etc.)</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># check server/client version</span></span><br><span class="line">$ kubectl version</span><br><span class="line"><span class="comment"># get workers</span></span><br><span class="line">$ kubectl get node</span><br><span class="line"><span class="comment"># get pods</span></span><br><span class="line">$ kubectl get pods</span><br><span class="line"><span class="comment"># get deployment</span></span><br><span class="line">$ kubectl get deploy</span><br><span class="line"><span class="comment"># get services</span></span><br><span class="line">$ kubectl get svc</span><br></pre></td></tr></table></figure><h3 id="More-kubectl-commands"><a href="#More-kubectl-commands" class="headerlink" title="More kubectl commands"></a>More kubectl commands</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl run kubernetes-bootcamp --image=jocatalin/kubernetes-bootcamp:v1 --port=8080</span><br><span class="line"><span class="comment"># check deploy/pods again</span></span><br><span class="line">$ kubectl get deploy</span><br><span class="line">$ kubectl get pods</span><br><span class="line"><span class="comment"># i.e. NAME: kubernetes-bootcamp-6b7849c495-p7dsw</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Then check log of the pod</span></span><br><span class="line">$ kubectl logs kubernetes-bootcamp-6b7849c495-p7dsw -f</span><br><span class="line"><span class="comment"># (ctrl-c out the following log)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># describe pod</span></span><br><span class="line">$ kubectl describe pods kubernetes-bootcamp-6b7849c495-p7dsw</span><br><span class="line"><span class="comment"># (Find the Mounts:/var/run/secrets/kubernetes.io/serviceaccount in the description)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Enter the running pod and verify the above path</span></span><br><span class="line">$ kubectl <span class="built_in">exec</span> -it kubernetes-bootcamp-6b7849c495-p7dsw bash</span><br><span class="line"><span class="comment"># Find out the certificate files in that path</span></span><br><span class="line">$ ls -l /var/run/secrets/kubernetes.io/serviceaccount </span><br><span class="line"><span class="comment"># Exit the pod</span></span><br><span class="line">$ <span class="built_in">exit</span></span><br><span class="line"><span class="comment"># These ca files are actually associate with the ca account, check that info by:</span></span><br><span class="line">$ kubectl get sa -o yaml</span><br><span class="line"><span class="comment"># can also output other pattern, e.g. json</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># check the "secret"</span></span><br><span class="line">$ kubectl get secrets -o yaml</span><br><span class="line"><span class="comment"># (The content of this secret has 3 sections that are mounted as three files in each pod as we see in above)</span></span><br></pre></td></tr></table></figure><blockquote><p>The “secret” are mounted to each created pod as files located in /var/run/secrets/… so that each pod can connect with api-server with https requests.</p></blockquote><h3 id="Use-‘apply’-or-‘create’-with-yaml-files"><a href="#Use-‘apply’-or-‘create’-with-yaml-files" class="headerlink" title="Use ‘apply’ or ‘create’ with yaml files"></a>Use ‘apply’ or ‘create’ with yaml files</h3><p>Kubectl ‘apply’ command is similar to ‘create’ command, but has rich properties.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> services</span><br><span class="line"><span class="comment"># Create a nginx pod and verify</span></span><br><span class="line">$ kubectl apply -f nginx-pod.yaml</span><br><span class="line">$ kubectl describe pod nginx</span><br><span class="line"><span class="comment"># (version here used is 1.7.9)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># vi nginx-pod.yaml and change image:nginx:1.7.9 -&gt; image:nginx:1.13, re-apply the yaml file</span></span><br><span class="line">$ kubectl apply -f nginx-pod.yaml</span><br><span class="line"><span class="comment"># (version here is now 1.13)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Another way to change version of running image is to use 'set' command</span></span><br><span class="line">$ kubectl <span class="built_in">set</span> image pods nginx nginx=nginx:1.7.9</span><br><span class="line"><span class="comment"># (reset the version to 1.7.9)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 'apply' command can be also used to create other resources</span></span><br><span class="line">$ kubectl apply -f nginx-deployment.yaml</span><br><span class="line">$ kubectl apply -f nginx-service.yaml</span><br><span class="line"></span><br><span class="line"><span class="comment"># Check the service is runing</span></span><br><span class="line">$ curl 192.168.56.104:20000</span><br><span class="line">$ curl 192.168.56.105:20000</span><br><span class="line"><span class="comment"># (Nginx welcome page should be displayed)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Verify the service</span></span><br><span class="line">$ kubectl get svc</span><br><span class="line"><span class="comment"># (copy the CLUSTER-IP for nginx-service here, e.g. 10.68.33.239) </span></span><br><span class="line"><span class="comment"># Use busybox image (sandbox within the cluster) for testing</span></span><br><span class="line">$ kubectl delete pod busybox</span><br><span class="line">$ kubectl run busybox --rm=<span class="literal">true</span> --image=busybox --restart=Never --tty -i</span><br><span class="line"><span class="comment"># In busybox container access nginx service with kube-proxy</span></span><br><span class="line">$ wget -qO - 10.68.33.239:8080</span><br><span class="line"><span class="comment"># One can also access the service directly through service name</span></span><br><span class="line">$ wget -qO - nginx-service:8080</span><br><span class="line"><span class="comment"># exit</span></span><br><span class="line">$ <span class="built_in">exit</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># clear-out the cluster after this demo session</span></span><br><span class="line">$ kubectl delete -f nginx-pod.yaml</span><br><span class="line">$ kubectl delete -f nginx-deployment.yaml</span><br><span class="line">$ kubectl delete -f nginx-service.yaml</span><br><span class="line">$ kubectl delete deploy kubernetes-bootcamp</span><br></pre></td></tr></table></figure><h2 id="Recommended-references"><a href="#Recommended-references" class="headerlink" title="Recommended references"></a>Recommended references</h2><p>Following YouTube links also provide some examples worth trying out:</p><p>[1] <span class="exturl" data-url="aHR0cHM6Ly93d3cueW91dHViZS5jb20vd2F0Y2g/dj1LMUh1T0x6UFNwVQ==" title="https://www.youtube.com/watch?v=K1HuOLzPSpU">https://www.youtube.com/watch?v=K1HuOLzPSpU<i class="fa fa-external-link"></i></span></p><p>[2] <span class="exturl" data-url="aHR0cHM6Ly93d3cueW91dHViZS5jb20vd2F0Y2g/dj15dTNIbE9Yb0VLaw==" title="https://www.youtube.com/watch?v=yu3HlOXoEKk">https://www.youtube.com/watch?v=yu3HlOXoEKk<i class="fa fa-external-link"></i></span></p><p>[3] <span class="exturl" data-url="aHR0cHM6Ly93d3cueW91dHViZS5jb20vd2F0Y2g/dj1rdlEzVlRfd0g5OA==" title="https://www.youtube.com/watch?v=kvQ3VT_wH98">https://www.youtube.com/watch?v=kvQ3VT_wH98<i class="fa fa-external-link"></i></span></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;This post demonstrate some Kubernetes basic commends.&lt;/p&gt;
&lt;h2 id=&quot;Server-Overview&quot;&gt;&lt;a href=&quot;#Server-Overview&quot; class=&quot;headerlink&quot; title=&quot;Server Overview&quot;&gt;&lt;/a&gt;Server Overview&lt;/h2&gt;&lt;p&gt;We have setup 3 virtual machines，each has 1 cpu and 1GB memory. Details：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&quot;center&quot;&gt;Server OS&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;IP Address&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;Node Type&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;CPU&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;Memory&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;Hostname&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;ubuntu16.04&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;192.168.56.103&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;master&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;1&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;1G&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;server01&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;ubuntu16.04&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;192.168.56.104&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;slave1&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;1&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;1G&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;server02&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;ubuntu16.04&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;192.168.56.105&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;slave2&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;1&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;1G&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;server03&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;blockquote&gt;
&lt;p&gt;To follow this demo, root privilege is required, ask system admin (Todd) for root access.&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
      <category term="k8s" scheme="https://ruby-.github.io/categories/k8s/"/>
    
    
      <category term="k8s, demo" scheme="https://ruby-.github.io/tags/k8s-demo/"/>
    
  </entry>
  
</feed>
